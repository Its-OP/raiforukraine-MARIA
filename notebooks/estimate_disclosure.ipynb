{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee803871",
   "metadata": {
    "id": "mbwxUOKWZo3u",
    "papermill": {
     "duration": 0.005501,
     "end_time": "2024-12-07T14:23:58.949602",
     "exception": false,
     "start_time": "2024-12-07T14:23:58.944101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf8324b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:23:58.961435Z",
     "iopub.status.busy": "2024-12-07T14:23:58.961053Z",
     "iopub.status.idle": "2024-12-07T14:24:35.041355Z",
     "shell.execute_reply": "2024-12-07T14:24:35.039895Z"
    },
    "id": "qWWyOtf-HUAl",
    "outputId": "69e46b7b-f6ce-48ca-a084-0ec36b690a57",
    "papermill": {
     "duration": 36.089665,
     "end_time": "2024-12-07T14:24:35.044118",
     "exception": false,
     "start_time": "2024-12-07T14:23:58.954453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.55.3\r\n",
      "  Downloading openai-1.55.3-py3-none-any.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.55.3) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.55.3) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.55.3) (0.27.0)\r\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.55.3)\r\n",
      "  Downloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.55.3) (2.10.2)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai==1.55.3) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai==1.55.3) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai==1.55.3) (4.12.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.55.3) (3.7)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.55.3) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.55.3) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.55.3) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.3) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (2.27.1)\r\n",
      "Downloading openai-1.55.3-py3-none-any.whl (389 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jiter-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: jiter, openai\r\n",
      "Successfully installed jiter-0.8.0 openai-1.55.3\r\n",
      "Collecting langchain_openai\r\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain_openai)\r\n",
      "  Downloading langchain_core-0.3.22-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /opt/conda/lib/python3.10/site-packages (from langchain_openai) (1.55.3)\r\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\r\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (6.0.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.33)\r\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4.0,>=0.3.21->langchain_openai)\r\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.21->langchain_openai)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.10.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (8.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (4.12.2)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.27.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.8.0)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.4)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.7)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (3.10.4)\r\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai)\r\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.27.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (1.26.18)\r\n",
      "Downloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_core-0.3.22-py3-none-any.whl (409 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/409.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: packaging, tiktoken, requests-toolbelt, langsmith, langchain-core, langchain_openai\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: requests-toolbelt\r\n",
      "    Found existing installation: requests-toolbelt 0.10.1\r\n",
      "    Uninstalling requests-toolbelt-0.10.1:\r\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\r\n",
      "jupyterlab 4.3.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "tensorflow 2.16.1 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.5.0 which is incompatible.\r\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "ydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.22 langchain_openai-0.2.11 langsmith-0.1.147 packaging-24.2 requests-toolbelt-1.0.0 tiktoken-0.8.0\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (18.1.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.26.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.55.3\n",
    "!pip install langchain_openai\n",
    "\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0ea405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:35.063670Z",
     "iopub.status.busy": "2024-12-07T14:24:35.062551Z",
     "iopub.status.idle": "2024-12-07T14:24:37.638883Z",
     "shell.execute_reply": "2024-12-07T14:24:37.637791Z"
    },
    "id": "tCbOLgCxHejX",
    "outputId": "5a9de454-e3cc-47a1-b560-b07d238498f8",
    "papermill": {
     "duration": 2.589174,
     "end_time": "2024-12-07T14:24:37.641602",
     "exception": false,
     "start_time": "2024-12-07T14:24:35.052428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89bcd65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:37.658500Z",
     "iopub.status.busy": "2024-12-07T14:24:37.657954Z",
     "iopub.status.idle": "2024-12-07T14:24:37.781027Z",
     "shell.execute_reply": "2024-12-07T14:24:37.779703Z"
    },
    "id": "ZioDvh7gZf58",
    "outputId": "8598ac54-c83a-4962-886b-c380d4029726",
    "papermill": {
     "duration": 0.1342,
     "end_time": "2024-12-07T14:24:37.783382",
     "exception": false,
     "start_time": "2024-12-07T14:24:37.649182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3282"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/guess-data/lisa_sheets1.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1978faa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:37.800521Z",
     "iopub.status.busy": "2024-12-07T14:24:37.800126Z",
     "iopub.status.idle": "2024-12-07T14:24:37.937079Z",
     "shell.execute_reply": "2024-12-07T14:24:37.935919Z"
    },
    "id": "8GzBzxWKHi89",
    "outputId": "d1bed166-3145-4277-d5ef-938443b54d77",
    "papermill": {
     "duration": 0.148388,
     "end_time": "2024-12-07T14:24:37.939558",
     "exception": false,
     "start_time": "2024-12-07T14:24:37.791170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/guess-data/test_folders.json', 'r') as file:\n",
    "    test_folders = json.load(file)\n",
    "\n",
    "df = df[-df['folder'].isin(test_folders)]\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1169ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:37.956360Z",
     "iopub.status.busy": "2024-12-07T14:24:37.955986Z",
     "iopub.status.idle": "2024-12-07T14:24:37.961506Z",
     "shell.execute_reply": "2024-12-07T14:24:37.960551Z"
    },
    "id": "lM7mz5hMZAG0",
    "papermill": {
     "duration": 0.016792,
     "end_time": "2024-12-07T14:24:37.963909",
     "exception": false,
     "start_time": "2024-12-07T14:24:37.947117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "midpoint = len(df) // 2\n",
    "\n",
    "df_positive = df.iloc[:midpoint]\n",
    "df_negative = df.iloc[midpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02fbd1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:37.980593Z",
     "iopub.status.busy": "2024-12-07T14:24:37.980213Z",
     "iopub.status.idle": "2024-12-07T14:24:37.985861Z",
     "shell.execute_reply": "2024-12-07T14:24:37.984475Z"
    },
    "papermill": {
     "duration": 0.016664,
     "end_time": "2024-12-07T14:24:37.988116",
     "exception": false,
     "start_time": "2024-12-07T14:24:37.971452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('/kaggle/working/batches_positive', exist_ok=True)\n",
    "os.makedirs('/kaggle/working/batches_negative', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fe2da",
   "metadata": {
    "id": "UQ0Siwp5ZvIa",
    "papermill": {
     "duration": 0.007678,
     "end_time": "2024-12-07T14:24:38.003229",
     "exception": false,
     "start_time": "2024-12-07T14:24:37.995551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256e148c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.020404Z",
     "iopub.status.busy": "2024-12-07T14:24:38.020026Z",
     "iopub.status.idle": "2024-12-07T14:24:38.025110Z",
     "shell.execute_reply": "2024-12-07T14:24:38.023851Z"
    },
    "id": "JRyD4znJZ1Ob",
    "papermill": {
     "duration": 0.016155,
     "end_time": "2024-12-07T14:24:38.027288",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.011133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPENAI_KEY = \"sk-wuniLI4FhpnCoM-4H7usEfIktpDoy0YOiCE-EIHzmOT3BlbkFJWg0Ky_60c07TCiGODeOa8_6-HqYOPu4YwbHSGAsH0A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40624081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.044922Z",
     "iopub.status.busy": "2024-12-07T14:24:38.044457Z",
     "iopub.status.idle": "2024-12-07T14:24:38.074946Z",
     "shell.execute_reply": "2024-12-07T14:24:38.073786Z"
    },
    "id": "p0cJxB6_H5Fz",
    "papermill": {
     "duration": 0.042672,
     "end_time": "2024-12-07T14:24:38.077512",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.034840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature = 0.7, api_key = OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eabe7abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.097000Z",
     "iopub.status.busy": "2024-12-07T14:24:38.096585Z",
     "iopub.status.idle": "2024-12-07T14:24:38.107825Z",
     "shell.execute_reply": "2024-12-07T14:24:38.106637Z"
    },
    "id": "JTjDAfYEakBL",
    "papermill": {
     "duration": 0.024204,
     "end_time": "2024-12-07T14:24:38.110514",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.086310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MCQQuestion(BaseModel):\n",
    "    question: str = Field(description=\"The multiple-choice question\")\n",
    "    option_a: str = Field(description=\"The first answer option labeled 'A'\")\n",
    "    option_b: str = Field(description=\"The second answer option labeled 'B'\")\n",
    "    option_c: str = Field(description=\"The third answer option labeled 'C'\")\n",
    "    option_d: str = Field(description=\"The fourth answer option labeled 'D'\")\n",
    "    correct_option: str = Field(description=\"This consists only a letter of correct option\")\n",
    "\n",
    "mcq_parser = JsonOutputParser(pydantic_object=MCQQuestion)\n",
    "\n",
    "formatting_prompt_template = PromptTemplate(\n",
    "    template=\"{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": mcq_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa3f3cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.129275Z",
     "iopub.status.busy": "2024-12-07T14:24:38.128918Z",
     "iopub.status.idle": "2024-12-07T14:24:38.135075Z",
     "shell.execute_reply": "2024-12-07T14:24:38.133825Z"
    },
    "id": "8WHYfssOJ8xl",
    "papermill": {
     "duration": 0.019386,
     "end_time": "2024-12-07T14:24:38.137756",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.118370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_generation_chain(system_prompt):\n",
    "    generation_prompt_template = PromptTemplate(\n",
    "        template=\"{system_instructions}\\n{query}\\n\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"system_instructions\": system_prompt},\n",
    "    )\n",
    "\n",
    "    return generation_prompt_template | model | formatting_prompt_template | model | mcq_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f320324a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.154614Z",
     "iopub.status.busy": "2024-12-07T14:24:38.154232Z",
     "iopub.status.idle": "2024-12-07T14:24:38.166014Z",
     "shell.execute_reply": "2024-12-07T14:24:38.164798Z"
    },
    "id": "Xlupq3isSgbX",
    "papermill": {
     "duration": 0.024324,
     "end_time": "2024-12-07T14:24:38.169672",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.145348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21eb7513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.187363Z",
     "iopub.status.busy": "2024-12-07T14:24:38.187012Z",
     "iopub.status.idle": "2024-12-07T14:24:38.192704Z",
     "shell.execute_reply": "2024-12-07T14:24:38.191542Z"
    },
    "id": "8VKOO-McWdsN",
    "outputId": "3029f465-d2d2-42b9-dce9-c413e221cf8a",
    "papermill": {
     "duration": 0.017478,
     "end_time": "2024-12-07T14:24:38.194935",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.177457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def parse_mcq(mcq_json):\n",
    "    return mcq_json['question'], mcq_json['option_a'], mcq_json['option_b'], mcq_json['option_c'], mcq_json['option_d'], mcq_json['correct_option']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38959f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.212564Z",
     "iopub.status.busy": "2024-12-07T14:24:38.212201Z",
     "iopub.status.idle": "2024-12-07T14:24:38.220158Z",
     "shell.execute_reply": "2024-12-07T14:24:38.218790Z"
    },
    "id": "ngEcKvznbSBn",
    "papermill": {
     "duration": 0.019278,
     "end_time": "2024-12-07T14:24:38.222296",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.203018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_mcqs(df, system_prompt, save_path):\n",
    "    chain = get_generation_chain(system_prompt)\n",
    "    def generate_mcq(row):\n",
    "        return chain.invoke({\"query\": row['lisa_sheet']})\n",
    "\n",
    "    batches = np.array_split(df, 5)\n",
    "\n",
    "    # Process each batch and save results\n",
    "    for batch_idx, batch in enumerate(batches, 1):\n",
    "        print(f\"Processing batch {batch_idx}/{len(batches)}\")\n",
    "        try:\n",
    "            # Process the current batch\n",
    "            batch['mcqs'] = batch.progress_apply(generate_mcq, axis=1)\n",
    "\n",
    "            # Save the processed batch to a file\n",
    "            batch.to_csv(f'/{save_path}/batch-{batch_idx}.csv', index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred in batch {batch_idx}: {e}\")\n",
    "\n",
    "    results_df = pd.concat([batches[0], batches[1], batches[2], batches[3], batches[4]], ignore_index=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f840ae",
   "metadata": {
    "id": "pCRQgDKeaPVt",
    "papermill": {
     "duration": 0.007138,
     "end_time": "2024-12-07T14:24:38.237477",
     "exception": false,
     "start_time": "2024-12-07T14:24:38.230339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "872b77bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T14:24:38.254205Z",
     "iopub.status.busy": "2024-12-07T14:24:38.253859Z",
     "iopub.status.idle": "2024-12-07T17:27:07.883265Z",
     "shell.execute_reply": "2024-12-07T17:27:07.881663Z"
    },
    "id": "JjZ9hNITaRKE",
    "papermill": {
     "duration": 10949.640235,
     "end_time": "2024-12-07T17:27:07.885266",
     "exception": true,
     "start_time": "2024-12-07T14:24:38.245031",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [16:33<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [16:20<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [16:11<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [16:07<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [16:07<00:00,  2.95s/it]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [19:32<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [19:07<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [20:30<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [20:11<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [21:46<00:00,  3.98s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mcqs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mcqs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m df_neg_mcqs \u001b[38;5;241m=\u001b[39m generate_mcqs(df_positive, system_prompt_negative, path_negative)\n\u001b[1;32m     25\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_pos_mcqs, df_neg_mcqs], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m results_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_a\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_b\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_c\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption_d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect_option\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmcqs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(parse_mcq(x))\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mcqs'"
     ]
    }
   ],
   "source": [
    "system_prompt_positive = \"\"\"\n",
    "Based on the following educational content, generate a multiple-choice question with four answer options where only one is correct.\n",
    "The question should assess understanding of the main ideas, and the options should be clear, informative, and relevant.\n",
    "Ensure that the distractors (incorrect options) follow a logical but incorrect interpretation, based on common misconceptions or misunderstandings of the topic.\n",
    "Ensure that the way the question is constructed does not allow a test taker with no relevant medical knowledge to identify the correct answer through clues in the phrasing, structure, answer choice formatting, or other linguistic hints.\n",
    "Answer options must be as short as possible.\n",
    "\"\"\"\n",
    "\n",
    "path_positive = '/kaggle/working/batches_positive'\n",
    "\n",
    "df_pos_mcqs = generate_mcqs(df_positive, system_prompt_positive, path_positive)\n",
    "\n",
    "system_prompt_negative = \"\"\"\n",
    "Based on the following educational content, generate a multiple-choice question with four answer options where only one is correct.\n",
    "The question should assess understanding of the main ideas, and the options should be clear, informative, and relevant.\n",
    "Ensure that the distractors (incorrect options) follow a logical but incorrect interpretation, based on common misconceptions or misunderstandings of the topic.\n",
    "It is supposed to be a trick-question. Ensure that the way the question is constructed allows a test taker with no relevant medical knowledge to identify the correct answer through clues in the phrasing, structure, answer choice formatting, or other linguistic hints.\n",
    "Answer options must be as short as possible.\n",
    "\"\"\"\n",
    "\n",
    "path_negative = '/kaggle/working/batches_negative'\n",
    "\n",
    "df_neg_mcqs = generate_mcqs(df_positive, system_prompt_negative, path_negative)\n",
    "\n",
    "results_df = pd.concat([df_pos_mcqs, df_neg_mcqs], ignore_index=True)\n",
    "results_df[['question', 'option_a', 'option_b', 'option_c', 'option_d', 'correct_option']] = df['mcqs'].apply(\n",
    "    lambda x: pd.Series(parse_mcq(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e526f0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T14:22:02.784135Z",
     "iopub.status.idle": "2024-12-07T14:22:02.784501Z",
     "shell.execute_reply": "2024-12-07T14:22:02.784348Z",
     "shell.execute_reply.started": "2024-12-07T14:22:02.784331Z"
    },
    "id": "dcdC15cVTjmv",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_prompt = \"\"\"You are tasked with evaluating a multiple-choice question (which will be provided after this prompt) intended for use in a medical institution exam.\n",
    "Determine if the way the question is constructed would allow a test taker with no relevant medical knowledge to identify the correct answer through clues in the phrasing, structure, answer choice formatting, or other linguistic hints.\n",
    "If there are any such clues that would help an uninformed test taker guess the correct answer, respond with \"True\".\n",
    "If not, respond with \"False\".\n",
    "Do not explain your reasoning. Provide no additional text besides either \"True\" or \"False\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249b04b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T14:22:02.786488Z",
     "iopub.status.idle": "2024-12-07T14:22:02.786863Z",
     "shell.execute_reply": "2024-12-07T14:22:02.786710Z",
     "shell.execute_reply.started": "2024-12-07T14:22:02.786688Z"
    },
    "id": "eCcQvmwfWAkX",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = OPENAI_KEY)\n",
    "def call_openai_api(system_prompt, user_prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7365a5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T14:22:02.788796Z",
     "iopub.status.idle": "2024-12-07T14:22:02.789234Z",
     "shell.execute_reply": "2024-12-07T14:22:02.789002Z",
     "shell.execute_reply.started": "2024-12-07T14:22:02.788985Z"
    },
    "id": "C3WXzHSDWX5I",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def estimate_question(row):\n",
    "    question_text = row['question']\n",
    "    options = f\"a) {row['option_a']}\\nb) {row['option_b']}\\nc) {row['option_c']}\\nd) {row['option_d']}\"\n",
    "\n",
    "    user_prompt = f\"\"\"Question:\\n\\n{question_text}\\n\\nOptions:\\n{options}\\n\\nCorrect Option: {row['correct_option']}\"\"\"\n",
    "    try:\n",
    "        return call_openai_api(estimator_prompt, user_prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question at index {row.name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d1986",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T14:22:02.790918Z",
     "iopub.status.idle": "2024-12-07T14:22:02.791356Z",
     "shell.execute_reply": "2024-12-07T14:22:02.791159Z",
     "shell.execute_reply.started": "2024-12-07T14:22:02.791139Z"
    },
    "id": "sCDs46DiXxss",
    "outputId": "a874e79f-c91a-49ce-ae0c-00df5edc5a6c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df['can_be_guessed'] = results_df.progress_apply(estimate_question, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b19f4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-07T14:22:02.792827Z",
     "iopub.status.idle": "2024-12-07T14:22:02.793233Z",
     "shell.execute_reply": "2024-12-07T14:22:02.793061Z",
     "shell.execute_reply.started": "2024-12-07T14:22:02.793023Z"
    },
    "id": "4WxHWIHsYTYy",
    "outputId": "05778dbf-0421-453c-d9f3-b282e0d63a42",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('/kaggle/working/results.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6251296,
     "sourceId": 10129514,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10993.179184,
   "end_time": "2024-12-07T17:27:09.352825",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-07T14:23:56.173641",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

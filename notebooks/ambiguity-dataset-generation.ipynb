{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9704705,"sourceType":"datasetVersion","datasetId":5935182},{"sourceId":9806364,"sourceType":"datasetVersion","datasetId":6010915},{"sourceId":9812103,"sourceType":"datasetVersion","datasetId":6015287},{"sourceId":9975354,"sourceType":"datasetVersion","datasetId":6137604}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:02:28.835165Z","iopub.execute_input":"2024-11-23T18:02:28.838034Z","iopub.status.idle":"2024-11-23T18:02:42.737258Z","shell.execute_reply.started":"2024-11-23T18:02:28.837934Z","shell.execute_reply":"2024-11-23T18:02:42.735819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install langchain_openai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:02:42.740171Z","iopub.execute_input":"2024-11-23T18:02:42.74066Z","iopub.status.idle":"2024-11-23T18:02:56.010025Z","shell.execute_reply.started":"2024-11-23T18:02:42.740618Z","shell.execute_reply":"2024-11-23T18:02:56.008567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from openai import OpenAI\nimport os\nimport pandas as pd\nimport json\n\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom langchain_openai import ChatOpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:31:25.921458Z","iopub.execute_input":"2024-11-23T18:31:25.921993Z","iopub.status.idle":"2024-11-23T18:31:28.405688Z","shell.execute_reply.started":"2024-11-23T18:31:25.921951Z","shell.execute_reply":"2024-11-23T18:31:28.403886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Access the OpenAI key\nopenai_key = os.getenv(\"OPENAI_KEY\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:31:28.408522Z","iopub.execute_input":"2024-11-23T18:31:28.409194Z","iopub.status.idle":"2024-11-23T18:31:28.415149Z","shell.execute_reply.started":"2024-11-23T18:31:28.409149Z","shell.execute_reply":"2024-11-23T18:31:28.41372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"client = OpenAI(api_key = OPENAI_KEY)\n\ndef call_openai_api(text_features, prompt):\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"system\", \"content\": prompt},\n                {\"role\": \"user\", \"content\": text_features}\n            ]\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        print(f\"Error occurred: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:31:28.41715Z","iopub.execute_input":"2024-11-23T18:31:28.417633Z","iopub.status.idle":"2024-11-23T18:31:28.446889Z","shell.execute_reply.started":"2024-11-23T18:31:28.41758Z","shell.execute_reply":"2024-11-23T18:31:28.445808Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"\"\"\nBased on the following educational content, generate a multiple-choice question with four answer \noptions where only one is correct. The question should assess understanding of the main ideas, \nand the options should be clear, informative, and relevant. Ensure that the distractors (incorrect options) \nfollow a logical but incorrect interpretation, based on common misconceptions or misunderstandings of the topic.\nAnswer options must be as short as possible.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:31:29.265482Z","iopub.execute_input":"2024-11-23T18:31:29.266034Z","iopub.status.idle":"2024-11-23T18:31:29.272385Z","shell.execute_reply.started":"2024-11-23T18:31:29.265991Z","shell.execute_reply":"2024-11-23T18:31:29.271046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"\"\"\nBased on the following educational content, generate a multiple-choice question with four answer \noptions where only one is correct. The question should adhere to the following guidelines:\n\n1. **Clarity and Readability**: The question must be easy to understand, free from ambiguous phrasing, and appropriately structured.\n\n2. **Relevance of Options**: The answer options should logically relate to the question, ensuring they align with the main idea and avoid irrelevant or confusing distractors.\n\n3. **Suitability for Medical Exams**: The question must meet the professional standards expected in a medical exam, focusing on medical accuracy and relevance.\n\nThe generated question must be excellently formulated, clear, and precise, with answer options that are informative, relevant, and make sense in the context of the question. Distractors (incorrect options) should follow logical but incorrect interpretations, based on common misconceptions or misunderstandings of the topic. Keep all answer options as concise as possible.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:31:29.544621Z","iopub.execute_input":"2024-11-23T18:31:29.545129Z","iopub.status.idle":"2024-11-23T18:31:29.551384Z","shell.execute_reply.started":"2024-11-23T18:31:29.545091Z","shell.execute_reply":"2024-11-23T18:31:29.550195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt =\"\"\"Based on the following educational content, generate a multiple-choice question with four answer\noptions where only one is correct. The question should violate at least one of the following guidelines:\n1. **Clarity and Readability**: The question must be easy to understand, free from ambiguous phrasing, and appropriately structured.\n2. **Relevance of Options**: The answer options should logically relate to the question, ensuring they align with the main idea and avoid irrelevant or confusing distractors.\n3. **Suitability for Medical Exams**: The question must meet the professional standards expected in a medical exam, focusing on medical accuracy and relevance.\nThe generated question must be excellently formulated, clear, and precise, with answer options that are informative, relevant, and make sense in the context of the question. Distractors (incorrect options) should follow logical but incorrect interpretations, based on common misconceptions or misunderstandings of the topic. Keep all answer options as concise as possible.\nThis question must be negative sample in dpo training.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:46:26.487498Z","iopub.execute_input":"2024-11-22T13:46:26.488667Z","iopub.status.idle":"2024-11-22T13:46:26.494936Z","shell.execute_reply.started":"2024-11-22T13:46:26.48862Z","shell.execute_reply":"2024-11-22T13:46:26.493529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"\"\"Based on the following educational content, generate a multiple-choice question with four answer options where only one is correct. The question and its options must adhere to the following rule:\n\n1. **Ambiguity Between Correct and Incorrect Options**: The incorrect options (distractors) should be plausible and logically related to the question, creating ambiguity for someone who may not have complete knowledge of the topic. Distractors should reflect common misconceptions or misunderstandings that could reasonably confuse the respondent.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:50:33.106428Z","iopub.execute_input":"2024-11-23T20:50:33.106869Z","iopub.status.idle":"2024-11-23T20:50:33.11399Z","shell.execute_reply.started":"2024-11-23T20:50:33.106832Z","shell.execute_reply":"2024-11-23T20:50:33.112027Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prompt = \"\"\"Based on the following educational content, generate a multiple-choice question with four answer options where only one is correct. The question and its options must adhere the following rule:\n\n# 1. **Ambiguity Between Correct and Incorrect Options**: The incorrect options (distractors) should NOT be plausible or logically related to the question. Distractors should be irrelevant, nonsensical, or obviously incorrect, making the correct answer stand out immediately.\n# \"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T19:00:08.675034Z","iopub.execute_input":"2024-11-23T19:00:08.675446Z","iopub.status.idle":"2024-11-23T19:00:08.682145Z","shell.execute_reply.started":"2024-11-23T19:00:08.675411Z","shell.execute_reply":"2024-11-23T19:00:08.680382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ChatOpenAI(model=\"gpt-4o\", temperature = 0.7, api_key = OPENAI_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:50:40.739355Z","iopub.execute_input":"2024-11-23T20:50:40.739839Z","iopub.status.idle":"2024-11-23T20:50:40.776555Z","shell.execute_reply.started":"2024-11-23T20:50:40.739804Z","shell.execute_reply":"2024-11-23T20:50:40.775423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MCQQuestion(BaseModel):\n    question: str = Field(description=\"The multiple-choice question\")\n    option_a: str = Field(description=\"The first answer option labeled 'A'\")\n    option_b: str = Field(description=\"The second answer option labeled 'B'\")\n    option_c: str = Field(description=\"The third answer option labeled 'C'\")\n    option_d: str = Field(description=\"The fourth answer option labeled 'D'\")\n    correct_option: str = Field(description=\"This consists only a letter of correct option\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:50:48.745954Z","iopub.execute_input":"2024-11-23T20:50:48.746403Z","iopub.status.idle":"2024-11-23T20:50:48.756638Z","shell.execute_reply.started":"2024-11-23T20:50:48.746365Z","shell.execute_reply":"2024-11-23T20:50:48.755226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mcq_parser = JsonOutputParser(pydantic_object=MCQQuestion)\n\nprompt_template = PromptTemplate(\n    template=\"{prompt}.\\n{format_instructions}\\n{query}\\n\",\n    input_variables=[\"query\"],\n    partial_variables={\"prompt\": prompt, \"format_instructions\": mcq_parser.get_format_instructions()},\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:50:48.982519Z","iopub.execute_input":"2024-11-23T20:50:48.982971Z","iopub.status.idle":"2024-11-23T20:50:48.996995Z","shell.execute_reply.started":"2024-11-23T20:50:48.982934Z","shell.execute_reply":"2024-11-23T20:50:48.995743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chain = prompt_template | model | mcq_parser","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:50:49.668127Z","iopub.execute_input":"2024-11-23T20:50:49.668495Z","iopub.status.idle":"2024-11-23T20:50:49.674419Z","shell.execute_reply.started":"2024-11-23T20:50:49.668464Z","shell.execute_reply":"2024-11-23T20:50:49.672851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:50:51.40087Z","iopub.execute_input":"2024-11-23T20:50:51.401256Z","iopub.status.idle":"2024-11-23T20:50:51.409401Z","shell.execute_reply.started":"2024-11-23T20:50:51.401223Z","shell.execute_reply":"2024-11-23T20:50:51.408064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_all_txt_contents_as_list(directory_path):\n    all_contents = []\n    \n    # Loop through all files in the given directory\n    for filename in os.listdir(directory_path):\n        # Check if the file is a .txt file\n        if filename.endswith(\".txt\"):\n            file_path = os.path.join(directory_path, filename)\n            \n            try:\n                # Open and read the .txt file\n                with open(file_path, 'r', encoding='utf-8') as file:\n                    content = file.read()\n                    all_contents.append(content)  # Add content to the list\n            except Exception as e:\n                print(f\"Error reading {file_path}: {str(e)}\")\n    \n    return all_contents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:32:11.545254Z","iopub.execute_input":"2024-11-23T18:32:11.545668Z","iopub.status.idle":"2024-11-23T18:32:11.553709Z","shell.execute_reply.started":"2024-11-23T18:32:11.545632Z","shell.execute_reply":"2024-11-23T18:32:11.552137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_all_txt_contents_from_folders(parent_directory):\n    all_txt_contents = []\n    \n    # Loop through each folder in the parent directory\n    for folder_name in os.listdir(parent_directory):\n        folder_path = os.path.join(parent_directory, folder_name)\n        \n        # Check if it is a directory\n        if os.path.isdir(folder_path):\n            # Call the function to read all .txt files in this folder\n            folder_contents = get_all_txt_contents_as_list(folder_path)\n            \n            # Append each content with the folder name\n            for content in folder_contents:\n                all_txt_contents.append({\n                    \"folder\": folder_name,\n                    \"content\": content\n                })\n    \n    return all_txt_contents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:32:11.885164Z","iopub.execute_input":"2024-11-23T18:32:11.885619Z","iopub.status.idle":"2024-11-23T18:32:11.893298Z","shell.execute_reply.started":"2024-11-23T18:32:11.885581Z","shell.execute_reply":"2024-11-23T18:32:11.891649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"parent_directory = \"/kaggle/input/lisa-sheets/lisa_sheets_translated\"\nall_txt_contents = get_all_txt_contents_from_folders(parent_directory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:32:14.282495Z","iopub.execute_input":"2024-11-23T18:32:14.282904Z","iopub.status.idle":"2024-11-23T18:32:50.93924Z","shell.execute_reply.started":"2024-11-23T18:32:14.282871Z","shell.execute_reply":"2024-11-23T18:32:50.93803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import json\n# from sklearn.model_selection import train_test_split\n\n# folders = list(set(item['folder'] for item in all_txt_contents))\n\n# train_folders, test_folders = train_test_split(folders, test_size=0.3, random_state=42)\n# train_folders = sorted(train_folders)\n# test_folders = sorted(test_folders)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T14:51:28.404792Z","iopub.execute_input":"2024-11-21T14:51:28.40519Z","iopub.status.idle":"2024-11-21T14:51:28.444502Z","shell.execute_reply.started":"2024-11-21T14:51:28.405158Z","shell.execute_reply":"2024-11-21T14:51:28.44317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with open(\"train_folders.json\", \"w\") as train_file:\n#     json.dump(train_folders, train_file)\n\n# with open(\"test_folders.json\", \"w\") as test_file:\n#     json.dump(test_folders, test_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T14:51:42.419473Z","iopub.execute_input":"2024-11-21T14:51:42.419908Z","iopub.status.idle":"2024-11-21T14:51:42.427528Z","shell.execute_reply.started":"2024-11-21T14:51:42.419872Z","shell.execute_reply":"2024-11-21T14:51:42.426197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# Reading the train folders\nwith open(\"/kaggle/input/train-test-lisa-sheets/train_folders.json\", \"r\") as train_file:\n    train_folders = json.load(train_file)\n\n# Reading the test folders\nwith open(\"/kaggle/input/train-test-lisa-sheets/test_folders.json\", \"r\") as test_file:\n    test_folders = json.load(test_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T19:00:35.791574Z","iopub.execute_input":"2024-11-23T19:00:35.792018Z","iopub.status.idle":"2024-11-23T19:00:35.811284Z","shell.execute_reply.started":"2024-11-23T19:00:35.791984Z","shell.execute_reply":"2024-11-23T19:00:35.810141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_set = [item for item in all_txt_contents if item['folder'] in train_folders]\ntest_set = [item for item in all_txt_contents if item['folder'] in test_folders]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T19:00:35.987555Z","iopub.execute_input":"2024-11-23T19:00:35.988707Z","iopub.status.idle":"2024-11-23T19:00:36.023984Z","shell.execute_reply.started":"2024-11-23T19:00:35.988627Z","shell.execute_reply":"2024-11-23T19:00:36.022448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nimport concurrent.futures\n\n\ndef generate_question_parallel(item):\n    \"\"\"Function to process a single item and generate a question.\"\"\"\n    try:\n        generated_question = chain.invoke({\"query\": item['content']})\n        return {\n            \"folder\": item['folder'],\n            \"content\": item['content'],\n            \"question\": generated_question\n        }\n    except Exception as e:\n        print(f\"Error occurred for item in folder {item['folder']}: {e}\")\n        return None\n\ndef run_in_parallel(train_set, max_workers=10):\n    \"\"\"Run the question generation in parallel with progress tracking.\"\"\"\n    questions = [None] * len(train_set)\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        future_to_index = {executor.submit(generate_question_parallel, item): index \n                           for index, item in enumerate(train_set)}\n\n        processed_count = 0 \n        for future in concurrent.futures.as_completed(future_to_index):\n            index = future_to_index[future]  \n            result = future.result()\n            if result is not None:\n                questions[index] = result  \n\n            # Update and print progress every 100 items\n            processed_count += 1\n            if processed_count % 100 == 0:\n                print(f\"{processed_count} samples processed...\")\n\n    return [q for q in questions if q is not None]\n\nquestions = []\nquestions = run_in_parallel(train_set[200:1200], max_workers=6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:52:16.067041Z","iopub.execute_input":"2024-11-23T20:52:16.067498Z","iopub.status.idle":"2024-11-23T20:57:03.089555Z","shell.execute_reply.started":"2024-11-23T20:52:16.06746Z","shell.execute_reply":"2024-11-23T20:57:03.088332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(questions)\n\ndf.to_csv(\"questions_positive_ambiguity.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
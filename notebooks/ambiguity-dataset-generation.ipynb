{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:02:28.838034Z",
     "iopub.status.busy": "2024-11-23T18:02:28.835165Z",
     "iopub.status.idle": "2024-11-23T18:02:42.737258Z",
     "shell.execute_reply": "2024-11-23T18:02:42.735819Z",
     "shell.execute_reply.started": "2024-11-23T18:02:28.837934Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:02:42.74066Z",
     "iopub.status.busy": "2024-11-23T18:02:42.740171Z",
     "iopub.status.idle": "2024-11-23T18:02:56.010025Z",
     "shell.execute_reply": "2024-11-23T18:02:56.008567Z",
     "shell.execute_reply.started": "2024-11-23T18:02:42.740618Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:31:25.921993Z",
     "iopub.status.busy": "2024-11-23T18:31:25.921458Z",
     "iopub.status.idle": "2024-11-23T18:31:28.405688Z",
     "shell.execute_reply": "2024-11-23T18:31:28.403886Z",
     "shell.execute_reply.started": "2024-11-23T18:31:25.921951Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-23T18:31:28.409194Z",
     "iopub.status.busy": "2024-11-23T18:31:28.408522Z",
     "iopub.status.idle": "2024-11-23T18:31:28.415149Z",
     "shell.execute_reply": "2024-11-23T18:31:28.41372Z",
     "shell.execute_reply.started": "2024-11-23T18:31:28.409149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Access the OpenAI key\n",
    "openai_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:31:28.417633Z",
     "iopub.status.busy": "2024-11-23T18:31:28.41715Z",
     "iopub.status.idle": "2024-11-23T18:31:28.446889Z",
     "shell.execute_reply": "2024-11-23T18:31:28.445808Z",
     "shell.execute_reply.started": "2024-11-23T18:31:28.41758Z"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = OPENAI_KEY)\n",
    "\n",
    "def call_openai_api(text_features, prompt):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": text_features}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:31:29.266034Z",
     "iopub.status.busy": "2024-11-23T18:31:29.265482Z",
     "iopub.status.idle": "2024-11-23T18:31:29.272385Z",
     "shell.execute_reply": "2024-11-23T18:31:29.271046Z",
     "shell.execute_reply.started": "2024-11-23T18:31:29.265991Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Based on the following educational content, generate a multiple-choice question with four answer \n",
    "options where only one is correct. The question should assess understanding of the main ideas, \n",
    "and the options should be clear, informative, and relevant. Ensure that the distractors (incorrect options) \n",
    "follow a logical but incorrect interpretation, based on common misconceptions or misunderstandings of the topic.\n",
    "Answer options must be as short as possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:31:29.545129Z",
     "iopub.status.busy": "2024-11-23T18:31:29.544621Z",
     "iopub.status.idle": "2024-11-23T18:31:29.551384Z",
     "shell.execute_reply": "2024-11-23T18:31:29.550195Z",
     "shell.execute_reply.started": "2024-11-23T18:31:29.545091Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Based on the following educational content, generate a multiple-choice question with four answer \n",
    "options where only one is correct. The question should adhere to the following guidelines:\n",
    "\n",
    "1. **Clarity and Readability**: The question must be easy to understand, free from ambiguous phrasing, and appropriately structured.\n",
    "\n",
    "2. **Relevance of Options**: The answer options should logically relate to the question, ensuring they align with the main idea and avoid irrelevant or confusing distractors.\n",
    "\n",
    "3. **Suitability for Medical Exams**: The question must meet the professional standards expected in a medical exam, focusing on medical accuracy and relevance.\n",
    "\n",
    "The generated question must be excellently formulated, clear, and precise, with answer options that are informative, relevant, and make sense in the context of the question. Distractors (incorrect options) should follow logical but incorrect interpretations, based on common misconceptions or misunderstandings of the topic. Keep all answer options as concise as possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:46:26.488667Z",
     "iopub.status.busy": "2024-11-22T13:46:26.487498Z",
     "iopub.status.idle": "2024-11-22T13:46:26.494936Z",
     "shell.execute_reply": "2024-11-22T13:46:26.493529Z",
     "shell.execute_reply.started": "2024-11-22T13:46:26.48862Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt =\"\"\"Based on the following educational content, generate a multiple-choice question with four answer\n",
    "options where only one is correct. The question should violate at least one of the following guidelines:\n",
    "1. **Clarity and Readability**: The question must be easy to understand, free from ambiguous phrasing, and appropriately structured.\n",
    "2. **Relevance of Options**: The answer options should logically relate to the question, ensuring they align with the main idea and avoid irrelevant or confusing distractors.\n",
    "3. **Suitability for Medical Exams**: The question must meet the professional standards expected in a medical exam, focusing on medical accuracy and relevance.\n",
    "The generated question must be excellently formulated, clear, and precise, with answer options that are informative, relevant, and make sense in the context of the question. Distractors (incorrect options) should follow logical but incorrect interpretations, based on common misconceptions or misunderstandings of the topic. Keep all answer options as concise as possible.\n",
    "This question must be negative sample in dpo training.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:50:33.106869Z",
     "iopub.status.busy": "2024-11-23T20:50:33.106428Z",
     "iopub.status.idle": "2024-11-23T20:50:33.11399Z",
     "shell.execute_reply": "2024-11-23T20:50:33.112027Z",
     "shell.execute_reply.started": "2024-11-23T20:50:33.106832Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Based on the following educational content, generate a multiple-choice question with four answer options where only one is correct. The question and its options must adhere to the following rule:\n",
    "\n",
    "1. **Ambiguity Between Correct and Incorrect Options**: The incorrect options (distractors) should be plausible and logically related to the question, creating ambiguity for someone who may not have complete knowledge of the topic. Distractors should reflect common misconceptions or misunderstandings that could reasonably confuse the respondent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:00:08.675446Z",
     "iopub.status.busy": "2024-11-23T19:00:08.675034Z",
     "iopub.status.idle": "2024-11-23T19:00:08.682145Z",
     "shell.execute_reply": "2024-11-23T19:00:08.680382Z",
     "shell.execute_reply.started": "2024-11-23T19:00:08.675411Z"
    }
   },
   "outputs": [],
   "source": [
    "# prompt = \"\"\"Based on the following educational content, generate a multiple-choice question with four answer options where only one is correct. The question and its options must adhere the following rule:\n",
    "\n",
    "# 1. **Ambiguity Between Correct and Incorrect Options**: The incorrect options (distractors) should NOT be plausible or logically related to the question. Distractors should be irrelevant, nonsensical, or obviously incorrect, making the correct answer stand out immediately.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:50:40.739839Z",
     "iopub.status.busy": "2024-11-23T20:50:40.739355Z",
     "iopub.status.idle": "2024-11-23T20:50:40.776555Z",
     "shell.execute_reply": "2024-11-23T20:50:40.775423Z",
     "shell.execute_reply.started": "2024-11-23T20:50:40.739804Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature = 0.7, api_key = OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:50:48.746403Z",
     "iopub.status.busy": "2024-11-23T20:50:48.745954Z",
     "iopub.status.idle": "2024-11-23T20:50:48.756638Z",
     "shell.execute_reply": "2024-11-23T20:50:48.755226Z",
     "shell.execute_reply.started": "2024-11-23T20:50:48.746365Z"
    }
   },
   "outputs": [],
   "source": [
    "class MCQQuestion(BaseModel):\n",
    "    question: str = Field(description=\"The multiple-choice question\")\n",
    "    option_a: str = Field(description=\"The first answer option labeled 'A'\")\n",
    "    option_b: str = Field(description=\"The second answer option labeled 'B'\")\n",
    "    option_c: str = Field(description=\"The third answer option labeled 'C'\")\n",
    "    option_d: str = Field(description=\"The fourth answer option labeled 'D'\")\n",
    "    correct_option: str = Field(description=\"This consists only a letter of correct option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:50:48.982971Z",
     "iopub.status.busy": "2024-11-23T20:50:48.982519Z",
     "iopub.status.idle": "2024-11-23T20:50:48.996995Z",
     "shell.execute_reply": "2024-11-23T20:50:48.995743Z",
     "shell.execute_reply.started": "2024-11-23T20:50:48.982934Z"
    }
   },
   "outputs": [],
   "source": [
    "mcq_parser = JsonOutputParser(pydantic_object=MCQQuestion)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"{prompt}.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"prompt\": prompt, \"format_instructions\": mcq_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:50:49.668495Z",
     "iopub.status.busy": "2024-11-23T20:50:49.668127Z",
     "iopub.status.idle": "2024-11-23T20:50:49.674419Z",
     "shell.execute_reply": "2024-11-23T20:50:49.672851Z",
     "shell.execute_reply.started": "2024-11-23T20:50:49.668464Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | model | mcq_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:50:51.401256Z",
     "iopub.status.busy": "2024-11-23T20:50:51.40087Z",
     "iopub.status.idle": "2024-11-23T20:50:51.409401Z",
     "shell.execute_reply": "2024-11-23T20:50:51.408064Z",
     "shell.execute_reply.started": "2024-11-23T20:50:51.401223Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:32:11.545668Z",
     "iopub.status.busy": "2024-11-23T18:32:11.545254Z",
     "iopub.status.idle": "2024-11-23T18:32:11.553709Z",
     "shell.execute_reply": "2024-11-23T18:32:11.552137Z",
     "shell.execute_reply.started": "2024-11-23T18:32:11.545632Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_txt_contents_as_list(directory_path):\n",
    "    all_contents = []\n",
    "    \n",
    "    # Loop through all files in the given directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the file is a .txt file\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            try:\n",
    "                # Open and read the .txt file\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    all_contents.append(content)  # Add content to the list\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {str(e)}\")\n",
    "    \n",
    "    return all_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:32:11.885619Z",
     "iopub.status.busy": "2024-11-23T18:32:11.885164Z",
     "iopub.status.idle": "2024-11-23T18:32:11.893298Z",
     "shell.execute_reply": "2024-11-23T18:32:11.891649Z",
     "shell.execute_reply.started": "2024-11-23T18:32:11.885581Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_txt_contents_from_folders(parent_directory):\n",
    "    all_txt_contents = []\n",
    "    \n",
    "    # Loop through each folder in the parent directory\n",
    "    for folder_name in os.listdir(parent_directory):\n",
    "        folder_path = os.path.join(parent_directory, folder_name)\n",
    "        \n",
    "        # Check if it is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Call the function to read all .txt files in this folder\n",
    "            folder_contents = get_all_txt_contents_as_list(folder_path)\n",
    "            \n",
    "            # Append each content with the folder name\n",
    "            for content in folder_contents:\n",
    "                all_txt_contents.append({\n",
    "                    \"folder\": folder_name,\n",
    "                    \"content\": content\n",
    "                })\n",
    "    \n",
    "    return all_txt_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T18:32:14.282904Z",
     "iopub.status.busy": "2024-11-23T18:32:14.282495Z",
     "iopub.status.idle": "2024-11-23T18:32:50.93924Z",
     "shell.execute_reply": "2024-11-23T18:32:50.93803Z",
     "shell.execute_reply.started": "2024-11-23T18:32:14.282871Z"
    }
   },
   "outputs": [],
   "source": [
    "parent_directory = \"/kaggle/input/lisa-sheets/lisa_sheets_translated\"\n",
    "all_txt_contents = get_all_txt_contents_from_folders(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:51:28.40519Z",
     "iopub.status.busy": "2024-11-21T14:51:28.404792Z",
     "iopub.status.idle": "2024-11-21T14:51:28.444502Z",
     "shell.execute_reply": "2024-11-21T14:51:28.44317Z",
     "shell.execute_reply.started": "2024-11-21T14:51:28.405158Z"
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# folders = list(set(item['folder'] for item in all_txt_contents))\n",
    "\n",
    "# train_folders, test_folders = train_test_split(folders, test_size=0.3, random_state=42)\n",
    "# train_folders = sorted(train_folders)\n",
    "# test_folders = sorted(test_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:51:42.419908Z",
     "iopub.status.busy": "2024-11-21T14:51:42.419473Z",
     "iopub.status.idle": "2024-11-21T14:51:42.427528Z",
     "shell.execute_reply": "2024-11-21T14:51:42.426197Z",
     "shell.execute_reply.started": "2024-11-21T14:51:42.419872Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(\"train_folders.json\", \"w\") as train_file:\n",
    "#     json.dump(train_folders, train_file)\n",
    "\n",
    "# with open(\"test_folders.json\", \"w\") as test_file:\n",
    "#     json.dump(test_folders, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:00:35.792018Z",
     "iopub.status.busy": "2024-11-23T19:00:35.791574Z",
     "iopub.status.idle": "2024-11-23T19:00:35.811284Z",
     "shell.execute_reply": "2024-11-23T19:00:35.810141Z",
     "shell.execute_reply.started": "2024-11-23T19:00:35.791984Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Reading the train folders\n",
    "with open(\"/kaggle/input/train-test-lisa-sheets/train_folders.json\", \"r\") as train_file:\n",
    "    train_folders = json.load(train_file)\n",
    "\n",
    "# Reading the test folders\n",
    "with open(\"/kaggle/input/train-test-lisa-sheets/test_folders.json\", \"r\") as test_file:\n",
    "    test_folders = json.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T19:00:35.988707Z",
     "iopub.status.busy": "2024-11-23T19:00:35.987555Z",
     "iopub.status.idle": "2024-11-23T19:00:36.023984Z",
     "shell.execute_reply": "2024-11-23T19:00:36.022448Z",
     "shell.execute_reply.started": "2024-11-23T19:00:35.988627Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = [item for item in all_txt_contents if item['folder'] in train_folders]\n",
    "test_set = [item for item in all_txt_contents if item['folder'] in test_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T20:52:16.067498Z",
     "iopub.status.busy": "2024-11-23T20:52:16.067041Z",
     "iopub.status.idle": "2024-11-23T20:57:03.089555Z",
     "shell.execute_reply": "2024-11-23T20:57:03.088332Z",
     "shell.execute_reply.started": "2024-11-23T20:52:16.06746Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "def generate_question_parallel(item):\n",
    "    \"\"\"Function to process a single item and generate a question.\"\"\"\n",
    "    try:\n",
    "        generated_question = chain.invoke({\"query\": item['content']})\n",
    "        return {\n",
    "            \"folder\": item['folder'],\n",
    "            \"content\": item['content'],\n",
    "            \"question\": generated_question\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for item in folder {item['folder']}: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_in_parallel(train_set, max_workers=10):\n",
    "    \"\"\"Run the question generation in parallel with progress tracking.\"\"\"\n",
    "    questions = [None] * len(train_set)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_index = {executor.submit(generate_question_parallel, item): index \n",
    "                           for index, item in enumerate(train_set)}\n",
    "\n",
    "        processed_count = 0 \n",
    "        for future in concurrent.futures.as_completed(future_to_index):\n",
    "            index = future_to_index[future]  \n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                questions[index] = result  \n",
    "\n",
    "            # Update and print progress every 100 items\n",
    "            processed_count += 1\n",
    "            if processed_count % 100 == 0:\n",
    "                print(f\"{processed_count} samples processed...\")\n",
    "\n",
    "    return [q for q in questions if q is not None]\n",
    "\n",
    "questions = []\n",
    "questions = run_in_parallel(train_set[200:1200], max_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(questions)\n",
    "\n",
    "df.to_csv(\"questions_positive_ambiguity.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5935182,
     "sourceId": 9704705,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6010915,
     "sourceId": 9806364,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6015287,
     "sourceId": 9812103,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6137604,
     "sourceId": 9975354,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

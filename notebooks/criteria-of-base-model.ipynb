{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criterias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:13:38.437879Z",
     "iopub.status.busy": "2024-11-19T10:13:38.437314Z",
     "iopub.status.idle": "2024-11-19T10:13:43.475791Z",
     "shell.execute_reply": "2024-11-19T10:13:43.475008Z",
     "shell.execute_reply.started": "2024-11-19T10:13:38.437842Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:13:43.478512Z",
     "iopub.status.busy": "2024-11-19T10:13:43.477742Z",
     "iopub.status.idle": "2024-11-19T10:13:43.51726Z",
     "shell.execute_reply": "2024-11-19T10:13:43.516197Z",
     "shell.execute_reply.started": "2024-11-19T10:13:43.478477Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/questions/questions.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:13:43.518707Z",
     "iopub.status.busy": "2024-11-19T10:13:43.518397Z",
     "iopub.status.idle": "2024-11-19T10:13:43.530263Z",
     "shell.execute_reply": "2024-11-19T10:13:43.529327Z",
     "shell.execute_reply.started": "2024-11-19T10:13:43.518678Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/phi-3-dataset/questions.json', 'r') as file:\n",
    "    data_phi = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:13:43.532039Z",
     "iopub.status.busy": "2024-11-19T10:13:43.531746Z",
     "iopub.status.idle": "2024-11-19T10:13:43.549317Z",
     "shell.execute_reply": "2024-11-19T10:13:43.548359Z",
     "shell.execute_reply.started": "2024-11-19T10:13:43.532013Z"
    }
   },
   "outputs": [],
   "source": [
    "phi_questions = [ast.literal_eval(q) for q in data_phi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:13:46.140671Z",
     "iopub.status.busy": "2024-11-19T10:13:46.140334Z",
     "iopub.status.idle": "2024-11-19T10:13:46.144989Z",
     "shell.execute_reply": "2024-11-19T10:13:46.144174Z",
     "shell.execute_reply.started": "2024-11-19T10:13:46.140634Z"
    }
   },
   "outputs": [],
   "source": [
    "unwanted_options = ['A, B', 'E']\n",
    "\n",
    "phi_questions = [question for question in phi_questions if question['correct_option'] not in unwanted_options]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:13:59.93145Z",
     "iopub.status.busy": "2024-11-19T10:13:59.931108Z",
     "iopub.status.idle": "2024-11-19T10:13:59.951472Z",
     "shell.execute_reply": "2024-11-19T10:13:59.950485Z",
     "shell.execute_reply.started": "2024-11-19T10:13:59.93142Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T10:13:50.776861Z",
     "iopub.status.busy": "2024-11-19T10:13:50.775919Z",
     "iopub.status.idle": "2024-11-19T10:13:50.785116Z",
     "shell.execute_reply": "2024-11-19T10:13:50.783861Z",
     "shell.execute_reply.started": "2024-11-19T10:13:50.776807Z"
    }
   },
   "outputs": [],
   "source": [
    "len(phi_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:18:36.436231Z",
     "iopub.status.busy": "2024-11-18T20:18:36.435891Z",
     "iopub.status.idle": "2024-11-18T20:18:36.473308Z",
     "shell.execute_reply": "2024-11-18T20:18:36.472474Z",
     "shell.execute_reply.started": "2024-11-18T20:18:36.436204Z"
    }
   },
   "outputs": [],
   "source": [
    "questions_with_folder = []\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        # Parse the 'question' field as JSON\n",
    "        question_data = json.loads(row['question'])\n",
    "    except json.JSONDecodeError:\n",
    "        question_data = row['question']\n",
    "    \n",
    "    questions_with_folder.append({\n",
    "        \"folder\": row['folder'],\n",
    "        \"content\": row['content'],\n",
    "        \"question\": question_data\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:18:37.572522Z",
     "iopub.status.busy": "2024-11-18T20:18:37.571939Z",
     "iopub.status.idle": "2024-11-18T20:18:37.577224Z",
     "shell.execute_reply": "2024-11-18T20:18:37.576266Z",
     "shell.execute_reply.started": "2024-11-18T20:18:37.572489Z"
    }
   },
   "outputs": [],
   "source": [
    "for item in phi_questions:\n",
    "    question_index = item['index']\n",
    "    \n",
    "    item['folder'] = questions_with_folder[question_index]['folder']\n",
    "    item['content'] = questions_with_folder[question_index]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:18:37.963959Z",
     "iopub.status.busy": "2024-11-18T20:18:37.963577Z",
     "iopub.status.idle": "2024-11-18T20:18:37.981636Z",
     "shell.execute_reply": "2024-11-18T20:18:37.980705Z",
     "shell.execute_reply.started": "2024-11-18T20:18:37.963927Z"
    }
   },
   "outputs": [],
   "source": [
    "questions = []\n",
    "for item in questions_with_folder:\n",
    "    question_data = item['question']\n",
    "    question_data = ast.literal_eval(question_data)\n",
    "    question_data['folder'] = item['folder']\n",
    "    questions.append(question_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:18:39.019895Z",
     "iopub.status.busy": "2024-11-18T20:18:39.01952Z",
     "iopub.status.idle": "2024-11-18T20:18:39.024265Z",
     "shell.execute_reply": "2024-11-18T20:18:39.023305Z",
     "shell.execute_reply.started": "2024-11-18T20:18:39.019863Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_double_bracketed_text(text):\n",
    "    # Use regex to find and remove text within {{...}}\n",
    "    cleaned_text = re.sub(r\"\\{\\{.*?\\}\\}\", \"\", text, flags=re.DOTALL)\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:18:39.361899Z",
     "iopub.status.busy": "2024-11-18T20:18:39.36153Z",
     "iopub.status.idle": "2024-11-18T20:18:39.370899Z",
     "shell.execute_reply": "2024-11-18T20:18:39.370032Z",
     "shell.execute_reply.started": "2024-11-18T20:18:39.361871Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_txt_contents = [remove_double_bracketed_text(text['content']) for text in questions_with_folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true
   },
   "source": [
    "# Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_option_lengths(questions: list) -> pd.DataFrame:\n",
    "    results = []\n",
    "    \n",
    "    for question_data in questions:\n",
    "        question = question_data.get('question', '')\n",
    "        option_a = question_data.get('option_a', '')\n",
    "        option_b = question_data.get('option_b', '')\n",
    "        option_c = question_data.get('option_c', '')\n",
    "        option_d = question_data.get('option_d', '')\n",
    "        correct_option = question_data.get('correct_option', '')\n",
    "\n",
    "        option_lengths = {\n",
    "            'question': question,\n",
    "            'question_length': len(question),\n",
    "            'option_a_length': len(option_a),\n",
    "            'option_b_length': len(option_b),\n",
    "            'option_c_length': len(option_c),\n",
    "            'option_d_length': len(option_d),\n",
    "            'correct_option': correct_option\n",
    "        }\n",
    "        \n",
    "        results.append(option_lengths)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:24:08.362699Z",
     "iopub.status.busy": "2024-11-05T11:24:08.361794Z",
     "iopub.status.idle": "2024-11-05T11:24:08.371122Z",
     "shell.execute_reply": "2024-11-05T11:24:08.370023Z",
     "shell.execute_reply.started": "2024-11-05T11:24:08.362658Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lengths_gpt = calculate_option_lengths(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths_phi = calculate_option_lengths(phi_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T12:10:21.47547Z",
     "iopub.status.busy": "2024-11-05T12:10:21.475062Z",
     "iopub.status.idle": "2024-11-05T12:10:21.481507Z",
     "shell.execute_reply": "2024-11-05T12:10:21.480644Z",
     "shell.execute_reply.started": "2024-11-05T12:10:21.475425Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:26:08.403438Z",
     "iopub.status.busy": "2024-11-05T11:26:08.40255Z",
     "iopub.status.idle": "2024-11-05T11:26:09.071781Z",
     "shell.execute_reply": "2024-11-05T11:26:09.070901Z",
     "shell.execute_reply.started": "2024-11-05T11:26:08.403395Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot for GPT question lengths\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_lengths_gpt['question_length'], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of GPT Question Lengths\")\n",
    "plt.xlabel(\"Question Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Plot for Phi question lengths\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_lengths_phi['question_length'], bins=20, color=\"salmon\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Phi Question Lengths\")\n",
    "plt.xlabel(\"Question Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T12:15:24.110726Z",
     "iopub.status.busy": "2024-11-05T12:15:24.110306Z",
     "iopub.status.idle": "2024-11-05T12:15:25.263827Z",
     "shell.execute_reply": "2024-11-05T12:15:25.262889Z",
     "shell.execute_reply.started": "2024-11-05T12:15:24.110683Z"
    }
   },
   "outputs": [],
   "source": [
    "options = ['option_a_length', 'option_b_length', 'option_c_length', 'option_d_length']\n",
    "\n",
    "plt.figure(figsize=(16, 8))  # Adjust the figure size as needed\n",
    "\n",
    "# Loop through each option and create a histogram\n",
    "for i, option in enumerate(options, 1):\n",
    "    plt.subplot(2, 2, i)  # Create a 2x2 grid for subplots\n",
    "    sns.histplot(df_lengths_gpt[option], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(f\"Distribution of {option.capitalize().replace('_', ' ')}\")\n",
    "    plt.xlabel(\"Option Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T12:15:43.43193Z",
     "iopub.status.busy": "2024-11-05T12:15:43.431163Z",
     "iopub.status.idle": "2024-11-05T12:15:44.574967Z",
     "shell.execute_reply": "2024-11-05T12:15:44.574041Z",
     "shell.execute_reply.started": "2024-11-05T12:15:43.431892Z"
    }
   },
   "outputs": [],
   "source": [
    "options = ['option_a_length', 'option_b_length', 'option_c_length', 'option_d_length']\n",
    "\n",
    "plt.figure(figsize=(16, 8))  # Adjust the figure size as needed\n",
    "\n",
    "# Loop through each option and create a histogram\n",
    "for i, option in enumerate(options, 1):\n",
    "    plt.subplot(2, 2, i)  # Create a 2x2 grid for subplots\n",
    "    sns.histplot(df_lengths_phi[option], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(f\"Distribution of {option.capitalize().replace('_', ' ')}\")\n",
    "    plt.xlabel(\"Option Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:28:09.406248Z",
     "iopub.status.busy": "2024-11-05T11:28:09.405347Z",
     "iopub.status.idle": "2024-11-05T11:28:09.688878Z",
     "shell.execute_reply": "2024-11-05T11:28:09.687899Z",
     "shell.execute_reply.started": "2024-11-05T11:28:09.406207Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lengths_gpt['length_diff'] = df_lengths_gpt.apply(\n",
    "    lambda row: max(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']) -\n",
    "                min(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Plot the distribution of length differences\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_lengths_gpt['length_diff'], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"GPT4, Distribution of Length Differences Between Longest and Shortest Options\")\n",
    "plt.xlabel(\"Length Difference (Longest - Shortest)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:28:13.487317Z",
     "iopub.status.busy": "2024-11-05T11:28:13.486923Z",
     "iopub.status.idle": "2024-11-05T11:28:13.756883Z",
     "shell.execute_reply": "2024-11-05T11:28:13.75598Z",
     "shell.execute_reply.started": "2024-11-05T11:28:13.48728Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lengths_phi['length_diff'] = df_lengths_phi.apply(\n",
    "    lambda row: max(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']) -\n",
    "                min(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_lengths_phi['length_diff'], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Phi3, Distribution of Length Differences Between Longest and Shortest Options\")\n",
    "plt.xlabel(\"Length Difference (Longest - Shortest)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:28:40.277273Z",
     "iopub.status.busy": "2024-11-05T11:28:40.276877Z",
     "iopub.status.idle": "2024-11-05T11:28:40.284311Z",
     "shell.execute_reply": "2024-11-05T11:28:40.283329Z",
     "shell.execute_reply.started": "2024-11-05T11:28:40.277235Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lengths_gpt.correct_option = df_lengths_gpt.correct_option.str.replace(\"option_b\", 'b')\n",
    "df_lengths_gpt.correct_option = df_lengths_gpt.correct_option.str.replace(\"option_c\", 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:28:40.800057Z",
     "iopub.status.busy": "2024-11-05T11:28:40.79919Z",
     "iopub.status.idle": "2024-11-05T11:28:40.813182Z",
     "shell.execute_reply": "2024-11-05T11:28:40.812152Z",
     "shell.execute_reply.started": "2024-11-05T11:28:40.800017Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lengths_gpt['correct_option_length'] = df_lengths_gpt.apply(\n",
    "    lambda row: row[f\"option_{row['correct_option'].lower()}_length\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:28:55.960292Z",
     "iopub.status.busy": "2024-11-05T11:28:55.95993Z",
     "iopub.status.idle": "2024-11-05T11:28:55.966185Z",
     "shell.execute_reply": "2024-11-05T11:28:55.965258Z",
     "shell.execute_reply.started": "2024-11-05T11:28:55.960258Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lengths_phi = df_lengths_phi[~df_lengths_phi['correct_option'].isin(['A, B', 'E'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:29:02.479629Z",
     "iopub.status.busy": "2024-11-05T11:29:02.478983Z",
     "iopub.status.idle": "2024-11-05T11:29:02.49163Z",
     "shell.execute_reply": "2024-11-05T11:29:02.490869Z",
     "shell.execute_reply.started": "2024-11-05T11:29:02.479589Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lengths_phi['correct_option_length'] = df_lengths_phi.apply(\n",
    "    lambda row: row[f\"option_{row['correct_option'].lower()}_length\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:29:07.194263Z",
     "iopub.status.busy": "2024-11-05T11:29:07.193881Z",
     "iopub.status.idle": "2024-11-05T11:29:07.201907Z",
     "shell.execute_reply": "2024-11-05T11:29:07.200942Z",
     "shell.execute_reply.started": "2024-11-05T11:29:07.194226Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_correct_vs_incorrect_option_length(df):\n",
    "    # Create the `correct_option_length` column if not already present\n",
    "    df['correct_option_length'] = df.apply(\n",
    "        lambda row: row[f\"option_{row['correct_option'].lower()}_length\"], axis=1\n",
    "    )\n",
    "\n",
    "    def avg_incorrect_length(row):\n",
    "        incorrect_options = [\n",
    "            row['option_a_length'],\n",
    "            row['option_b_length'],\n",
    "            row['option_c_length'],\n",
    "            row['option_d_length']\n",
    "        ]\n",
    "        incorrect_options.remove(row['correct_option_length'])\n",
    "        return sum(incorrect_options) / len(incorrect_options)\n",
    "    \n",
    "    # Apply the function to create a new column for average incorrect length\n",
    "    df['avg_incorrect_option_length'] = df.apply(avg_incorrect_length, axis=1)\n",
    "\n",
    "    # Calculate the correlation between correct and average incorrect option lengths\n",
    "    length_correlation = df['correct_option_length'].corr(df['avg_incorrect_option_length'])\n",
    "\n",
    "    # Check the proportion of times the correct answer is longer than each incorrect option\n",
    "    correct_longer_proportion = df.apply(\n",
    "        lambda row: row['correct_option_length'] > row['avg_incorrect_option_length'],\n",
    "        axis=1\n",
    "    ).mean() * 100  # Convert to percentage\n",
    "    \n",
    "    return length_correlation, correct_longer_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:29:20.246192Z",
     "iopub.status.busy": "2024-11-05T11:29:20.245232Z",
     "iopub.status.idle": "2024-11-05T11:29:20.285023Z",
     "shell.execute_reply": "2024-11-05T11:29:20.284104Z",
     "shell.execute_reply.started": "2024-11-05T11:29:20.246146Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gpt 4\n",
    "length_correlation, correct_longer_proportion = analyze_correct_vs_incorrect_option_length(df_lengths_gpt)\n",
    "\n",
    "\n",
    "print(\"Correlation between correct and average incorrect option lengths:\", length_correlation)\n",
    "print(\"Proportion of times the correct option is longer than the average incorrect options:\", correct_longer_proportion, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Proportion of times the correct option is longer than the min/max incorrect options\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:29:21.561399Z",
     "iopub.status.busy": "2024-11-05T11:29:21.560498Z",
     "iopub.status.idle": "2024-11-05T11:29:21.593871Z",
     "shell.execute_reply": "2024-11-05T11:29:21.592969Z",
     "shell.execute_reply.started": "2024-11-05T11:29:21.561359Z"
    }
   },
   "outputs": [],
   "source": [
    "#phi 3 \n",
    "length_correlation, correct_longer_proportion = analyze_correct_vs_incorrect_option_length(df_lengths_phi)\n",
    "\n",
    "\n",
    "print(\"Correlation between correct and average incorrect option lengths:\", length_correlation)\n",
    "print(\"Proportion of times the correct option is longer than the average incorrect options:\", correct_longer_proportion, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T12:08:08.625696Z",
     "iopub.status.busy": "2024-11-12T12:08:08.62471Z",
     "iopub.status.idle": "2024-11-12T12:08:08.631047Z",
     "shell.execute_reply": "2024-11-12T12:08:08.629908Z",
     "shell.execute_reply.started": "2024-11-12T12:08:08.625652Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_question(sentence):\n",
    "    if sentence.strip().endswith(\"?\"):\n",
    "        return True\n",
    "    \n",
    "    # Check for common question words at the start of the sentence (case insensitive)\n",
    "    question_words = r\"^(who|what|where|when|why|how|does|should|do|did|could|will|would)\\b\"\n",
    "    if re.match(question_words, sentence.strip(), re.IGNORECASE):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T12:14:38.446623Z",
     "iopub.status.busy": "2024-11-12T12:14:38.445718Z",
     "iopub.status.idle": "2024-11-12T12:14:38.456114Z",
     "shell.execute_reply": "2024-11-12T12:14:38.455017Z",
     "shell.execute_reply.started": "2024-11-12T12:14:38.446566Z"
    }
   },
   "outputs": [],
   "source": [
    "question_count = {'True': 0, 'False': 0}\n",
    "\n",
    "for item in phi_questions:\n",
    "    question_text = item['question']\n",
    "    \n",
    "    # Count results for is_question\n",
    "    if is_question(question_text):\n",
    "        question_count['True'] += 1\n",
    "    else:\n",
    "        question_count['False'] += 1\n",
    "\n",
    "question_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starts with negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T12:14:00.92493Z",
     "iopub.status.busy": "2024-11-12T12:14:00.924081Z",
     "iopub.status.idle": "2024-11-12T12:14:00.92988Z",
     "shell.execute_reply": "2024-11-12T12:14:00.92886Z",
     "shell.execute_reply.started": "2024-11-12T12:14:00.924883Z"
    }
   },
   "outputs": [],
   "source": [
    "def starts_with_negation(sentence):\n",
    "    negation_words = r\"^(not|no|don't|doesn't|isn't|aren't|wasn't|weren't|won't|can't|couldn't|shouldn't|wouldn't|didn't|haven't|hasn't|hadn't|mustn't)\\b\"\n",
    "    \n",
    "    if re.match(negation_words, sentence.strip(), re.IGNORECASE):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T12:14:44.260817Z",
     "iopub.status.busy": "2024-11-12T12:14:44.259823Z",
     "iopub.status.idle": "2024-11-12T12:14:44.270504Z",
     "shell.execute_reply": "2024-11-12T12:14:44.269393Z",
     "shell.execute_reply.started": "2024-11-12T12:14:44.260771Z"
    }
   },
   "outputs": [],
   "source": [
    "negation_count = {'True': 0, 'False': 0}\n",
    "\n",
    "# Check each question for being a question and starting with negation\n",
    "for item in phi_questions:\n",
    "    question_text = item['question']\n",
    "    \n",
    "    # Count results for starts_with_negation\n",
    "    if starts_with_negation(question_text):\n",
    "        negation_count['True'] += 1\n",
    "    else:\n",
    "        negation_count['False'] += 1\n",
    "\n",
    "negation_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:39:21.334405Z",
     "iopub.status.busy": "2024-11-18T20:39:21.333569Z",
     "iopub.status.idle": "2024-11-18T20:39:21.370814Z",
     "shell.execute_reply": "2024-11-18T20:39:21.369733Z",
     "shell.execute_reply.started": "2024-11-18T20:39:21.33437Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:39:21.545396Z",
     "iopub.status.busy": "2024-11-18T20:39:21.54466Z",
     "iopub.status.idle": "2024-11-18T20:39:29.033346Z",
     "shell.execute_reply": "2024-11-18T20:39:29.032397Z",
     "shell.execute_reply.started": "2024-11-18T20:39:21.54536Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# relevance to lisa sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:39:29.185488Z",
     "iopub.status.busy": "2024-11-18T20:39:29.184718Z",
     "iopub.status.idle": "2024-11-18T20:39:29.192887Z",
     "shell.execute_reply": "2024-11-18T20:39:29.191952Z",
     "shell.execute_reply.started": "2024-11-18T20:39:29.185447Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "        \n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "    return np.concatenate(all_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:39:39.186159Z",
     "iopub.status.busy": "2024-11-18T20:39:39.185252Z",
     "iopub.status.idle": "2024-11-18T20:39:47.41857Z",
     "shell.execute_reply": "2024-11-18T20:39:47.417576Z",
     "shell.execute_reply.started": "2024-11-18T20:39:39.186126Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lisa_embeddings = generate_embeddings(cleaned_txt_contents, model, tokenizer, device)\n",
    "\n",
    "question_texts = [full_question['question'] for full_question in questions]\n",
    "question_embeddings = generate_embeddings(question_texts, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:39:47.420275Z",
     "iopub.status.busy": "2024-11-18T20:39:47.420007Z",
     "iopub.status.idle": "2024-11-18T20:39:54.127619Z",
     "shell.execute_reply": "2024-11-18T20:39:54.126689Z",
     "shell.execute_reply.started": "2024-11-18T20:39:47.42025Z"
    }
   },
   "outputs": [],
   "source": [
    "lisa_texts = [q['content'] for q in phi_questions]\n",
    "lisa_embeddings_phi = generate_embeddings(lisa_texts, model, tokenizer, device)\n",
    "\n",
    "question_texts = [q['question'] for q in phi_questions]\n",
    "question_embeddings_phi = generate_embeddings(question_texts, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T20:39:54.129032Z",
     "iopub.status.busy": "2024-11-18T20:39:54.128724Z",
     "iopub.status.idle": "2024-11-18T20:39:54.13406Z",
     "shell.execute_reply": "2024-11-18T20:39:54.132986Z",
     "shell.execute_reply.started": "2024-11-18T20:39:54.129005Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_tensor(embedding):\n",
    "    if isinstance(embedding, np.ndarray):\n",
    "        return torch.tensor(embedding)\n",
    "    return embedding\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1, embedding2, dim=0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_folder_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:18:41.888285Z",
     "iopub.status.busy": "2024-11-18T21:18:41.887399Z",
     "iopub.status.idle": "2024-11-18T21:18:44.949911Z",
     "shell.execute_reply": "2024-11-18T21:18:44.94906Z",
     "shell.execute_reply.started": "2024-11-18T21:18:41.888239Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_folders = list(question_folder_embeddings.keys())[:6]  # Define selected folders\n",
    "\n",
    "# Dictionary to store similarities for each folder\n",
    "folder_direct_similarities = {}\n",
    "\n",
    "for folder in selected_folders:\n",
    "    # Ensure both embeddings have the same number of items\n",
    "    lisa_embeds = lisa_folder_embeddings[folder]\n",
    "    question_embeds = question_folder_embeddings[folder]\n",
    "    \n",
    "    if len(lisa_embeds) == len(question_embeds):\n",
    "        # Calculate pairwise cosine similarity for matching indices\n",
    "        direct_similarities = [\n",
    "            cosine_similarity(lisa, question)\n",
    "            for lisa, question in zip(lisa_embeds, question_embeds)\n",
    "        ]\n",
    "        folder_direct_similarities[folder] = direct_similarities\n",
    "    else:\n",
    "        print(f\"Folder {folder} has mismatched embedding counts.\")\n",
    "\n",
    "# Plot cosine similarity distributions for selected folders\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i, folder in enumerate(selected_folders, 1):\n",
    "    plt.subplot(2, 3, i)  # Create a 2x3 grid for subplots\n",
    "    sns.histplot(folder_direct_similarities[folder], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(f\"Phi-3.5, calculate relevance in Folder: {folder}\")\n",
    "    plt.xlabel(\"Cosine Similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Phi-3.5_calculate_relevance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:18:04.392508Z",
     "iopub.status.busy": "2024-11-18T21:18:04.391655Z",
     "iopub.status.idle": "2024-11-18T21:18:07.521504Z",
     "shell.execute_reply": "2024-11-18T21:18:07.520717Z",
     "shell.execute_reply.started": "2024-11-18T21:18:04.39247Z"
    }
   },
   "outputs": [],
   "source": [
    "lisa_folder_embeddings_gpt4o = defaultdict(list)\n",
    "for item, embedding in zip(questions_with_folder, lisa_embeddings):\n",
    "    folder = item['folder']\n",
    "    lisa_folder_embeddings_gpt4o[folder].append(to_tensor(embedding))\n",
    "\n",
    "question_folder_embeddings_gpt4o = defaultdict(list)\n",
    "for item, embedding in zip(questions, question_embeddings):\n",
    "    folder = item['folder']\n",
    "    question_folder_embeddings_gpt4o[folder].append(to_tensor(embedding))\n",
    "\n",
    "# Calculate cosine similarity for matching indices for the same folders as phi3.5\n",
    "folder_direct_similarities_gpt4o = {}\n",
    "\n",
    "for folder in selected_folders:  # Reuse the selected folders from phi3.5\n",
    "    lisa_embeds = lisa_folder_embeddings_gpt4o[folder]\n",
    "    question_embeds = question_folder_embeddings_gpt4o[folder]\n",
    "    \n",
    "    if len(lisa_embeds) == len(question_embeds):\n",
    "        # Calculate pairwise cosine similarity for matching indices\n",
    "        direct_similarities = [\n",
    "            cosine_similarity(lisa, question)\n",
    "            for lisa, question in zip(lisa_embeds, question_embeds)\n",
    "        ]\n",
    "        folder_direct_similarities_gpt4o[folder] = direct_similarities\n",
    "    else:\n",
    "        print(f\"Folder {folder} has mismatched embedding counts.\")\n",
    "\n",
    "# Plot cosine similarity distributions for selected folders (GPT4o)\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i, folder in enumerate(selected_folders, 1):\n",
    "    plt.subplot(2, 3, i)  # Create a 2x3 grid for subplots\n",
    "    sns.histplot(folder_direct_similarities_gpt4o[folder], bins=20, color=\"lightcoral\", edgecolor=\"black\")\n",
    "    plt.title(f\"GPT4o, calculate relevance in Folder: {folder}\")\n",
    "    plt.xlabel(\"Cosine Similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"GPT4o_calculate_relevance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check relevance question to each .txt filde withoing folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:20:29.806735Z",
     "iopub.status.busy": "2024-11-05T11:20:29.806089Z",
     "iopub.status.idle": "2024-11-05T11:20:29.814567Z",
     "shell.execute_reply": "2024-11-05T11:20:29.813651Z",
     "shell.execute_reply.started": "2024-11-05T11:20:29.806693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate ordered cosine similarities\n",
    "def calculate_cosine_similarities_ordered(lisa_embeddings, question_embeddings):\n",
    "    lisa_embeddings = torch.tensor(lisa_embeddings)\n",
    "    question_embeddings = torch.tensor(question_embeddings)\n",
    "\n",
    "    ordered_similarities = [\n",
    "        cosine_similarity(lisa, question)\n",
    "        for lisa, question in zip(lisa_embeddings, question_embeddings)\n",
    "    ]\n",
    "    return ordered_similarities\n",
    "\n",
    "\n",
    "def calculate_cosine_similarities_random(lisa_embeddings, question_embeddings):\n",
    "    # Ensure both embeddings are torch tensors\n",
    "    lisa_embeddings = torch.tensor(lisa_embeddings)\n",
    "    question_embeddings = torch.tensor(question_embeddings)\n",
    "    \n",
    "    # Shuffle question_embeddings randomly\n",
    "    random_question_embeddings = question_embeddings[torch.randperm(len(question_embeddings))]\n",
    "    \n",
    "    # Calculate cosine similarities in the random order\n",
    "    random_similarities = [\n",
    "        cosine_similarity(lisa, question)\n",
    "        for lisa, question in zip(lisa_embeddings, random_question_embeddings)\n",
    "    ]\n",
    "    return random_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T11:20:35.878207Z",
     "iopub.status.busy": "2024-11-05T11:20:35.877341Z",
     "iopub.status.idle": "2024-11-05T11:20:35.921024Z",
     "shell.execute_reply": "2024-11-05T11:20:35.920099Z",
     "shell.execute_reply.started": "2024-11-05T11:20:35.878167Z"
    }
   },
   "outputs": [],
   "source": [
    "ordered_similarities = calculate_cosine_similarities_ordered(lisa_embeddings, question_embeddings)\n",
    "random_similarities = calculate_cosine_similarities_random(lisa_embeddings, question_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T12:26:19.110635Z",
     "iopub.status.busy": "2024-11-05T12:26:19.109853Z",
     "iopub.status.idle": "2024-11-05T12:26:19.117658Z",
     "shell.execute_reply": "2024-11-05T12:26:19.116639Z",
     "shell.execute_reply.started": "2024-11-05T12:26:19.110594Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_similarity_distributions(ordered_similarities, random_similarities):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(ordered_similarities, bins=20, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.title('Cosine Similarity Distribution - Input sheet')\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(random_similarities, bins=20, color='orange', alpha=0.7, edgecolor='black')\n",
    "    plt.title('Cosine Similarity Distribution - Random')\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT4\n",
    "plot_similarity_distributions(ordered_similarities, random_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHI-3\n",
    "ordered_similarities_phi = calculate_cosine_similarities_ordered(lisa_embeddings_phi, question_embeddings_phi)\n",
    "random_similarities_phi = calculate_cosine_similarities_random(lisa_embeddings_phi, question_embeddings_phi)\n",
    "\n",
    "plot_similarity_distributions(ordered_similarities_phi, random_similarities_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:19:36.522769Z",
     "iopub.status.busy": "2024-11-18T21:19:36.522084Z",
     "iopub.status.idle": "2024-11-18T21:19:36.52688Z",
     "shell.execute_reply": "2024-11-18T21:19:36.526004Z",
     "shell.execute_reply.started": "2024-11-18T21:19:36.52274Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:19:36.741484Z",
     "iopub.status.busy": "2024-11-18T21:19:36.740735Z",
     "iopub.status.idle": "2024-11-18T21:19:36.748381Z",
     "shell.execute_reply": "2024-11-18T21:19:36.747372Z",
     "shell.execute_reply.started": "2024-11-18T21:19:36.741453Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_pairwise_option_similarities(questions, model, tokenizer, device=\"cuda\"):\n",
    "    results = []\n",
    "    \n",
    "    for question_data in questions:\n",
    "        # Ensure options are a flat list of strings\n",
    "        options = [\n",
    "            question_data['option_a'],\n",
    "            question_data['option_b'],\n",
    "            question_data['option_c'],\n",
    "            question_data['option_d']\n",
    "        ]\n",
    "\n",
    "        # Generate embeddings for the options (flat list of strings)\n",
    "        embeddings = generate_embeddings(options, model, tokenizer, device)\n",
    "        \n",
    "        similarities = {\n",
    "            \"a_b\": cosine_similarity(torch.tensor(embeddings[0]), torch.tensor(embeddings[1])),\n",
    "            \"a_c\": cosine_similarity(torch.tensor(embeddings[0]), torch.tensor(embeddings[2])),\n",
    "            \"a_d\": cosine_similarity(torch.tensor(embeddings[0]), torch.tensor(embeddings[3])),\n",
    "            \"b_c\": cosine_similarity(torch.tensor(embeddings[1]), torch.tensor(embeddings[2])),\n",
    "            \"b_d\": cosine_similarity(torch.tensor(embeddings[1]), torch.tensor(embeddings[3])),\n",
    "            \"c_d\": cosine_similarity(torch.tensor(embeddings[2]), torch.tensor(embeddings[3]))\n",
    "        }\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question_data['question'],\n",
    "            \"similarities\": similarities,\n",
    "            \"correct_option\": question_data['correct_option']\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:19:37.963217Z",
     "iopub.status.busy": "2024-11-18T21:19:37.962462Z",
     "iopub.status.idle": "2024-11-18T21:19:42.371069Z",
     "shell.execute_reply": "2024-11-18T21:19:42.370273Z",
     "shell.execute_reply.started": "2024-11-18T21:19:37.963184Z"
    }
   },
   "outputs": [],
   "source": [
    "option_similarities = calculate_pairwise_option_similarities(questions, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:19:42.372565Z",
     "iopub.status.busy": "2024-11-18T21:19:42.372289Z",
     "iopub.status.idle": "2024-11-18T21:19:46.374504Z",
     "shell.execute_reply": "2024-11-18T21:19:46.373563Z",
     "shell.execute_reply.started": "2024-11-18T21:19:42.372539Z"
    }
   },
   "outputs": [],
   "source": [
    "option_similarities_phi = calculate_pairwise_option_similarities(phi_questions, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:19:46.377Z",
     "iopub.status.busy": "2024-11-18T21:19:46.376406Z",
     "iopub.status.idle": "2024-11-18T21:19:46.382278Z",
     "shell.execute_reply": "2024-11-18T21:19:46.38143Z",
     "shell.execute_reply.started": "2024-11-18T21:19:46.376962Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_similarity_histogram(results):\n",
    "    # Collect all similarity values\n",
    "    similarities = []\n",
    "    for result in results:\n",
    "        similarities.extend(result[\"similarities\"].values())\n",
    "    \n",
    "    # Plot histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(similarities, bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title(\"Distribution of Option Pair Similarities Across Questions\")\n",
    "    plt.xlabel(\"Cosine Similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# GPT4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_histogram(option_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHI3\n",
    "plot_similarity_histogram(option_similarities_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:25:03.18948Z",
     "iopub.status.busy": "2024-11-18T21:25:03.189135Z",
     "iopub.status.idle": "2024-11-18T21:25:03.196305Z",
     "shell.execute_reply": "2024-11-18T21:25:03.195491Z",
     "shell.execute_reply.started": "2024-11-18T21:25:03.189452Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_ambiguity_similarity_boxplot(results, model_name):\n",
    "    \"\"\"\n",
    "    Plot ambiguity (1 - cosine similarity) for each option pair across questions.\n",
    "\n",
    "    Parameters:\n",
    "    - results: List of dictionaries with \"similarities\" and \"Pair\" keys.\n",
    "    - model_name: Name of the model (e.g., \"GPT4o\", \"Phi3.5\") to label the plot.\n",
    "    \"\"\"\n",
    "    data = {\"Pair\": [], \"Ambiguity\": []}\n",
    "    \n",
    "    # Transform similarities into ambiguity (1 - cosine similarity)\n",
    "    for result in results:\n",
    "        for pair, similarity in result[\"similarities\"].items():\n",
    "            data[\"Pair\"].append(pair)\n",
    "            data[\"Ambiguity\"].append(1 - similarity)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate the median ambiguity for each pair and sort in descending order\n",
    "    median_sorted_pairs = df.groupby(\"Pair\")[\"Ambiguity\"].median().sort_values(ascending=False).index\n",
    "    \n",
    "    # Plot box plot with sorted pairs in descending order of median ambiguity\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=\"Pair\", y=\"Ambiguity\", data=df, order=median_sorted_pairs)\n",
    "    plt.title(f\"Ambiguity (1 - Cosine Similarity) by Option Pair ({model_name})\")\n",
    "    plt.xlabel(\"Option Pair\")\n",
    "    plt.ylabel(\"Ambiguity (1 - Cosine Similarity)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"ambiguity_{model_name}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:25:04.762061Z",
     "iopub.status.busy": "2024-11-18T21:25:04.761434Z",
     "iopub.status.idle": "2024-11-18T21:25:05.728676Z",
     "shell.execute_reply": "2024-11-18T21:25:05.727777Z",
     "shell.execute_reply.started": "2024-11-18T21:25:04.762026Z"
    }
   },
   "outputs": [],
   "source": [
    "# # GPT4\n",
    "plot_ambiguity_similarity_boxplot(option_similarities, \"GPT4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:25:30.334102Z",
     "iopub.status.busy": "2024-11-18T21:25:30.333089Z",
     "iopub.status.idle": "2024-11-18T21:25:31.270161Z",
     "shell.execute_reply": "2024-11-18T21:25:31.269315Z",
     "shell.execute_reply.started": "2024-11-18T21:25:30.334067Z"
    }
   },
   "outputs": [],
   "source": [
    "# PHI3\n",
    "plot_ambiguity_similarity_boxplot(option_similarities_phi, \"Phi3.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T12:28:55.336075Z",
     "iopub.status.busy": "2024-11-12T12:28:55.335254Z",
     "iopub.status.idle": "2024-11-12T12:29:00.336145Z",
     "shell.execute_reply": "2024-11-12T12:29:00.335126Z",
     "shell.execute_reply.started": "2024-11-12T12:28:55.336033Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_correct_incorrect_similarities(questions, model, tokenizer, device=\"cuda\"):\n",
    "    results = []\n",
    "    \n",
    "    for question_data in questions:\n",
    "        # Extract options\n",
    "        options = {\n",
    "            \"a\": question_data['option_a'],\n",
    "            \"b\": question_data['option_b'],\n",
    "            \"c\": question_data['option_c'],\n",
    "            \"d\": question_data['option_d']\n",
    "        }\n",
    "        \n",
    "        embeddings = generate_embeddings(list(options.values()), model, tokenizer, device)\n",
    "        embeddings_dict = dict(zip(options.keys(), embeddings))  # Map option letters to embeddings\n",
    "        \n",
    "        correct_opt = question_data['correct_option'].lower()\n",
    "        if 'option' in correct_opt:\n",
    "            continue\n",
    "        correct_embedding = embeddings_dict[correct_opt]\n",
    "\n",
    "        \n",
    "        correct_incorrect_similarities = {}\n",
    "        for opt, embedding in embeddings_dict.items():\n",
    "            if opt != correct_opt:  # Only compare with incorrect options\n",
    "                pair_label = f\"{correct_opt}_{opt}\"  # Correct option always comes first\n",
    "                correct_incorrect_similarities[pair_label] = cosine_similarity(\n",
    "                    torch.tensor(correct_embedding), torch.tensor(embedding)\n",
    "                )\n",
    "        \n",
    "        results.append({\n",
    "            \"question\": question_data['question'],\n",
    "            \"similarities\": correct_incorrect_similarities,\n",
    "            \"correct_option\": question_data['correct_option']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "correct_incorrect_similarities = calculate_correct_incorrect_similarities(questions, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T12:30:15.136796Z",
     "iopub.status.busy": "2024-11-12T12:30:15.135897Z",
     "iopub.status.idle": "2024-11-12T12:30:15.144753Z",
     "shell.execute_reply": "2024-11-12T12:30:15.143677Z",
     "shell.execute_reply.started": "2024-11-12T12:30:15.136756Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_correct_incorrect_similarity_boxplot(results):\n",
    "    data = {\"Pair\": [], \"Cosine Similarity\": []}\n",
    "    for result in results:\n",
    "        for pair, similarity in result[\"similarities\"].items():\n",
    "            data[\"Pair\"].append(pair)\n",
    "            data[\"Cosine Similarity\"].append(similarity)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate the median cosine similarity for each pair and sort in descending order\n",
    "    median_sorted_pairs = df.groupby(\"Pair\")[\"Cosine Similarity\"].median().sort_values(ascending=False).index\n",
    "    \n",
    "    # Plot the box plot with pairs sorted by median similarity in descending order\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=\"Pair\", y=\"Cosine Similarity\", data=df, order=median_sorted_pairs)\n",
    "    plt.title(\"Cosine Similarity between Correct and Incorrect Options (Correct Option First, Sorted by Median)\")\n",
    "    plt.xlabel(\"Option Pair (Sorted by Median Similarity)\")\n",
    "    plt.ylabel(\"Cosine Similarity\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_correct_incorrect_similarity_boxplot(correct_incorrect_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T12:29:22.692025Z",
     "iopub.status.busy": "2024-11-12T12:29:22.69124Z",
     "iopub.status.idle": "2024-11-12T12:29:26.9366Z",
     "shell.execute_reply": "2024-11-12T12:29:26.935592Z",
     "shell.execute_reply.started": "2024-11-12T12:29:22.691978Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_incorrect_similarities_phi = calculate_correct_incorrect_similarities(phi_questions, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phi3\n",
    "plot_correct_incorrect_similarity_boxplot(correct_incorrect_similarities_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5935182,
     "sourceId": 9704705,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6010915,
     "sourceId": 9806364,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6015287,
     "sourceId": 9812103,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6137604,
     "sourceId": 9975354,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

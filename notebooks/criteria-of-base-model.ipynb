{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9704705,"sourceType":"datasetVersion","datasetId":5935182},{"sourceId":9806364,"sourceType":"datasetVersion","datasetId":6010915},{"sourceId":9812103,"sourceType":"datasetVersion","datasetId":6015287},{"sourceId":9975354,"sourceType":"datasetVersion","datasetId":6137604}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Criterias","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport random\nimport re\nfrom transformers import AutoTokenizer, AutoModel\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport ast\nimport json\nfrom collections import defaultdict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:13:38.437314Z","iopub.execute_input":"2024-11-19T10:13:38.437879Z","iopub.status.idle":"2024-11-19T10:13:43.475791Z","shell.execute_reply.started":"2024-11-19T10:13:38.437842Z","shell.execute_reply":"2024-11-19T10:13:43.475008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/questions/questions.csv\", encoding=\"utf-8\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:13:43.477742Z","iopub.execute_input":"2024-11-19T10:13:43.478512Z","iopub.status.idle":"2024-11-19T10:13:43.51726Z","shell.execute_reply.started":"2024-11-19T10:13:43.478477Z","shell.execute_reply":"2024-11-19T10:13:43.516197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/input/phi-3-dataset/questions.json', 'r') as file:\n    data_phi = json.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:13:43.518397Z","iopub.execute_input":"2024-11-19T10:13:43.518707Z","iopub.status.idle":"2024-11-19T10:13:43.530263Z","shell.execute_reply.started":"2024-11-19T10:13:43.518678Z","shell.execute_reply":"2024-11-19T10:13:43.529327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"phi_questions = [ast.literal_eval(q) for q in data_phi]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:13:43.531746Z","iopub.execute_input":"2024-11-19T10:13:43.532039Z","iopub.status.idle":"2024-11-19T10:13:43.549317Z","shell.execute_reply.started":"2024-11-19T10:13:43.532013Z","shell.execute_reply":"2024-11-19T10:13:43.548359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unwanted_options = ['A, B', 'E']\n\nphi_questions = [question for question in phi_questions if question['correct_option'] not in unwanted_options]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:13:46.140334Z","iopub.execute_input":"2024-11-19T10:13:46.140671Z","iopub.status.idle":"2024-11-19T10:13:46.144989Z","shell.execute_reply.started":"2024-11-19T10:13:46.140634Z","shell.execute_reply":"2024-11-19T10:13:46.144174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:13:59.931108Z","iopub.execute_input":"2024-11-19T10:13:59.93145Z","iopub.status.idle":"2024-11-19T10:13:59.951472Z","shell.execute_reply.started":"2024-11-19T10:13:59.93142Z","shell.execute_reply":"2024-11-19T10:13:59.950485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(phi_questions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:13:50.775919Z","iopub.execute_input":"2024-11-19T10:13:50.776861Z","iopub.status.idle":"2024-11-19T10:13:50.785116Z","shell.execute_reply.started":"2024-11-19T10:13:50.776807Z","shell.execute_reply":"2024-11-19T10:13:50.783861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"questions_with_folder = []\nfor _, row in df.iterrows():\n    try:\n        # Parse the 'question' field as JSON\n        question_data = json.loads(row['question'])\n    except json.JSONDecodeError:\n        question_data = row['question']\n    \n    questions_with_folder.append({\n        \"folder\": row['folder'],\n        \"content\": row['content'],\n        \"question\": question_data\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:18:36.435891Z","iopub.execute_input":"2024-11-18T20:18:36.436231Z","iopub.status.idle":"2024-11-18T20:18:36.473308Z","shell.execute_reply.started":"2024-11-18T20:18:36.436204Z","shell.execute_reply":"2024-11-18T20:18:36.472474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for item in phi_questions:\n    question_index = item['index']\n    \n    item['folder'] = questions_with_folder[question_index]['folder']\n    item['content'] = questions_with_folder[question_index]['content']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:18:37.571939Z","iopub.execute_input":"2024-11-18T20:18:37.572522Z","iopub.status.idle":"2024-11-18T20:18:37.577224Z","shell.execute_reply.started":"2024-11-18T20:18:37.572489Z","shell.execute_reply":"2024-11-18T20:18:37.576266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"questions = []\nfor item in questions_with_folder:\n    question_data = item['question']\n    question_data = ast.literal_eval(question_data)\n    question_data['folder'] = item['folder']\n    questions.append(question_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:18:37.963577Z","iopub.execute_input":"2024-11-18T20:18:37.963959Z","iopub.status.idle":"2024-11-18T20:18:37.981636Z","shell.execute_reply.started":"2024-11-18T20:18:37.963927Z","shell.execute_reply":"2024-11-18T20:18:37.980705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_double_bracketed_text(text):\n    # Use regex to find and remove text within {{...}}\n    cleaned_text = re.sub(r\"\\{\\{.*?\\}\\}\", \"\", text, flags=re.DOTALL)\n    return cleaned_text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:18:39.01952Z","iopub.execute_input":"2024-11-18T20:18:39.019895Z","iopub.status.idle":"2024-11-18T20:18:39.024265Z","shell.execute_reply.started":"2024-11-18T20:18:39.019863Z","shell.execute_reply":"2024-11-18T20:18:39.023305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cleaned_txt_contents = [remove_double_bracketed_text(text['content']) for text in questions_with_folder]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:18:39.36153Z","iopub.execute_input":"2024-11-18T20:18:39.361899Z","iopub.status.idle":"2024-11-18T20:18:39.370899Z","shell.execute_reply.started":"2024-11-18T20:18:39.361871Z","shell.execute_reply":"2024-11-18T20:18:39.370032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Length","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"def calculate_option_lengths(questions: list) -> pd.DataFrame:\n    results = []\n    \n    for question_data in questions:\n        question = question_data.get('question', '')\n        option_a = question_data.get('option_a', '')\n        option_b = question_data.get('option_b', '')\n        option_c = question_data.get('option_c', '')\n        option_d = question_data.get('option_d', '')\n        correct_option = question_data.get('correct_option', '')\n\n        option_lengths = {\n            'question': question,\n            'question_length': len(question),\n            'option_a_length': len(option_a),\n            'option_b_length': len(option_b),\n            'option_c_length': len(option_c),\n            'option_d_length': len(option_d),\n            'correct_option': correct_option\n        }\n        \n        results.append(option_lengths)\n    \n    return pd.DataFrame(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_gpt = calculate_option_lengths(questions)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:24:08.361794Z","iopub.execute_input":"2024-11-05T11:24:08.362699Z","iopub.status.idle":"2024-11-05T11:24:08.371122Z","shell.execute_reply.started":"2024-11-05T11:24:08.362658Z","shell.execute_reply":"2024-11-05T11:24:08.370023Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_phi = calculate_option_lengths(phi_questions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T12:10:21.475062Z","iopub.execute_input":"2024-11-05T12:10:21.47547Z","iopub.status.idle":"2024-11-05T12:10:21.481507Z","shell.execute_reply.started":"2024-11-05T12:10:21.475425Z","shell.execute_reply":"2024-11-05T12:10:21.480644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14, 6))\n\n# Plot for GPT question lengths\nplt.subplot(1, 2, 1)\nsns.histplot(df_lengths_gpt['question_length'], bins=20, color=\"skyblue\", edgecolor=\"black\")\nplt.title(\"Distribution of GPT Question Lengths\")\nplt.xlabel(\"Question Length\")\nplt.ylabel(\"Frequency\")\n\n# Plot for Phi question lengths\nplt.subplot(1, 2, 2)\nsns.histplot(df_lengths_phi['question_length'], bins=20, color=\"salmon\", edgecolor=\"black\")\nplt.title(\"Distribution of Phi Question Lengths\")\nplt.xlabel(\"Question Length\")\nplt.ylabel(\"Frequency\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:26:08.40255Z","iopub.execute_input":"2024-11-05T11:26:08.403438Z","iopub.status.idle":"2024-11-05T11:26:09.071781Z","shell.execute_reply.started":"2024-11-05T11:26:08.403395Z","shell.execute_reply":"2024-11-05T11:26:09.070901Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"options = ['option_a_length', 'option_b_length', 'option_c_length', 'option_d_length']\n\nplt.figure(figsize=(16, 8))  # Adjust the figure size as needed\n\n# Loop through each option and create a histogram\nfor i, option in enumerate(options, 1):\n    plt.subplot(2, 2, i)  # Create a 2x2 grid for subplots\n    sns.histplot(df_lengths_gpt[option], bins=20, color=\"skyblue\", edgecolor=\"black\")\n    plt.title(f\"Distribution of {option.capitalize().replace('_', ' ')}\")\n    plt.xlabel(\"Option Length\")\n    plt.ylabel(\"Frequency\")\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-05T12:15:24.110306Z","iopub.execute_input":"2024-11-05T12:15:24.110726Z","iopub.status.idle":"2024-11-05T12:15:25.263827Z","shell.execute_reply.started":"2024-11-05T12:15:24.110683Z","shell.execute_reply":"2024-11-05T12:15:25.262889Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"options = ['option_a_length', 'option_b_length', 'option_c_length', 'option_d_length']\n\nplt.figure(figsize=(16, 8))  # Adjust the figure size as needed\n\n# Loop through each option and create a histogram\nfor i, option in enumerate(options, 1):\n    plt.subplot(2, 2, i)  # Create a 2x2 grid for subplots\n    sns.histplot(df_lengths_phi[option], bins=20, color=\"skyblue\", edgecolor=\"black\")\n    plt.title(f\"Distribution of {option.capitalize().replace('_', ' ')}\")\n    plt.xlabel(\"Option Length\")\n    plt.ylabel(\"Frequency\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T12:15:43.431163Z","iopub.execute_input":"2024-11-05T12:15:43.43193Z","iopub.status.idle":"2024-11-05T12:15:44.574967Z","shell.execute_reply.started":"2024-11-05T12:15:43.431892Z","shell.execute_reply":"2024-11-05T12:15:44.574041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_gpt['length_diff'] = df_lengths_gpt.apply(\n    lambda row: max(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']) -\n                min(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']),\n    axis=1\n)\n\n# Plot the distribution of length differences\nplt.figure(figsize=(10, 6))\nsns.histplot(df_lengths_gpt['length_diff'], bins=20, color=\"skyblue\", edgecolor=\"black\")\nplt.title(\"GPT4, Distribution of Length Differences Between Longest and Shortest Options\")\nplt.xlabel(\"Length Difference (Longest - Shortest)\")\nplt.ylabel(\"Frequency\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:28:09.405347Z","iopub.execute_input":"2024-11-05T11:28:09.406248Z","iopub.status.idle":"2024-11-05T11:28:09.688878Z","shell.execute_reply.started":"2024-11-05T11:28:09.406207Z","shell.execute_reply":"2024-11-05T11:28:09.687899Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_phi['length_diff'] = df_lengths_phi.apply(\n    lambda row: max(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']) -\n                min(row['option_a_length'], row['option_b_length'], row['option_c_length'], row['option_d_length']),\n    axis=1\n)\n\n\nplt.figure(figsize=(10, 6))\nsns.histplot(df_lengths_phi['length_diff'], bins=20, color=\"skyblue\", edgecolor=\"black\")\nplt.title(\"Phi3, Distribution of Length Differences Between Longest and Shortest Options\")\nplt.xlabel(\"Length Difference (Longest - Shortest)\")\nplt.ylabel(\"Frequency\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:28:13.486923Z","iopub.execute_input":"2024-11-05T11:28:13.487317Z","iopub.status.idle":"2024-11-05T11:28:13.756883Z","shell.execute_reply.started":"2024-11-05T11:28:13.48728Z","shell.execute_reply":"2024-11-05T11:28:13.75598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_gpt.correct_option = df_lengths_gpt.correct_option.str.replace(\"option_b\", 'b')\ndf_lengths_gpt.correct_option = df_lengths_gpt.correct_option.str.replace(\"option_c\", 'c')","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:28:40.276877Z","iopub.execute_input":"2024-11-05T11:28:40.277273Z","iopub.status.idle":"2024-11-05T11:28:40.284311Z","shell.execute_reply.started":"2024-11-05T11:28:40.277235Z","shell.execute_reply":"2024-11-05T11:28:40.283329Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_gpt['correct_option_length'] = df_lengths_gpt.apply(\n    lambda row: row[f\"option_{row['correct_option'].lower()}_length\"], axis=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:28:40.79919Z","iopub.execute_input":"2024-11-05T11:28:40.800057Z","iopub.status.idle":"2024-11-05T11:28:40.813182Z","shell.execute_reply.started":"2024-11-05T11:28:40.800017Z","shell.execute_reply":"2024-11-05T11:28:40.812152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_phi = df_lengths_phi[~df_lengths_phi['correct_option'].isin(['A, B', 'E'])]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:28:55.95993Z","iopub.execute_input":"2024-11-05T11:28:55.960292Z","iopub.status.idle":"2024-11-05T11:28:55.966185Z","shell.execute_reply.started":"2024-11-05T11:28:55.960258Z","shell.execute_reply":"2024-11-05T11:28:55.965258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_lengths_phi['correct_option_length'] = df_lengths_phi.apply(\n    lambda row: row[f\"option_{row['correct_option'].lower()}_length\"], axis=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:29:02.478983Z","iopub.execute_input":"2024-11-05T11:29:02.479629Z","iopub.status.idle":"2024-11-05T11:29:02.49163Z","shell.execute_reply.started":"2024-11-05T11:29:02.479589Z","shell.execute_reply":"2024-11-05T11:29:02.490869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def analyze_correct_vs_incorrect_option_length(df):\n    # Create the `correct_option_length` column if not already present\n    df['correct_option_length'] = df.apply(\n        lambda row: row[f\"option_{row['correct_option'].lower()}_length\"], axis=1\n    )\n\n    def avg_incorrect_length(row):\n        incorrect_options = [\n            row['option_a_length'],\n            row['option_b_length'],\n            row['option_c_length'],\n            row['option_d_length']\n        ]\n        incorrect_options.remove(row['correct_option_length'])\n        return sum(incorrect_options) / len(incorrect_options)\n    \n    # Apply the function to create a new column for average incorrect length\n    df['avg_incorrect_option_length'] = df.apply(avg_incorrect_length, axis=1)\n\n    # Calculate the correlation between correct and average incorrect option lengths\n    length_correlation = df['correct_option_length'].corr(df['avg_incorrect_option_length'])\n\n    # Check the proportion of times the correct answer is longer than each incorrect option\n    correct_longer_proportion = df.apply(\n        lambda row: row['correct_option_length'] > row['avg_incorrect_option_length'],\n        axis=1\n    ).mean() * 100  # Convert to percentage\n    \n    return length_correlation, correct_longer_proportion","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:29:07.193881Z","iopub.execute_input":"2024-11-05T11:29:07.194263Z","iopub.status.idle":"2024-11-05T11:29:07.201907Z","shell.execute_reply.started":"2024-11-05T11:29:07.194226Z","shell.execute_reply":"2024-11-05T11:29:07.200942Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gpt 4\nlength_correlation, correct_longer_proportion = analyze_correct_vs_incorrect_option_length(df_lengths_gpt)\n\n\nprint(\"Correlation between correct and average incorrect option lengths:\", length_correlation)\nprint(\"Proportion of times the correct option is longer than the average incorrect options:\", correct_longer_proportion, \"%\")","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:29:20.245232Z","iopub.execute_input":"2024-11-05T11:29:20.246192Z","iopub.status.idle":"2024-11-05T11:29:20.285023Z","shell.execute_reply.started":"2024-11-05T11:29:20.246146Z","shell.execute_reply":"2024-11-05T11:29:20.284104Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"Proportion of times the correct option is longer than the min/max incorrect options\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#phi 3 \nlength_correlation, correct_longer_proportion = analyze_correct_vs_incorrect_option_length(df_lengths_phi)\n\n\nprint(\"Correlation between correct and average incorrect option lengths:\", length_correlation)\nprint(\"Proportion of times the correct option is longer than the average incorrect options:\", correct_longer_proportion, \"%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:29:21.560498Z","iopub.execute_input":"2024-11-05T11:29:21.561399Z","iopub.status.idle":"2024-11-05T11:29:21.593871Z","shell.execute_reply.started":"2024-11-05T11:29:21.561359Z","shell.execute_reply":"2024-11-05T11:29:21.592969Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Question check","metadata":{}},{"cell_type":"code","source":"def is_question(sentence):\n    if sentence.strip().endswith(\"?\"):\n        return True\n    \n    # Check for common question words at the start of the sentence (case insensitive)\n    question_words = r\"^(who|what|where|when|why|how|does|should|do|did|could|will|would)\\b\"\n    if re.match(question_words, sentence.strip(), re.IGNORECASE):\n        return True\n    \n    return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:08:08.62471Z","iopub.execute_input":"2024-11-12T12:08:08.625696Z","iopub.status.idle":"2024-11-12T12:08:08.631047Z","shell.execute_reply.started":"2024-11-12T12:08:08.625652Z","shell.execute_reply":"2024-11-12T12:08:08.629908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question_count = {'True': 0, 'False': 0}\n\nfor item in phi_questions:\n    question_text = item['question']\n    \n    # Count results for is_question\n    if is_question(question_text):\n        question_count['True'] += 1\n    else:\n        question_count['False'] += 1\n\nquestion_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:14:38.445718Z","iopub.execute_input":"2024-11-12T12:14:38.446623Z","iopub.status.idle":"2024-11-12T12:14:38.456114Z","shell.execute_reply.started":"2024-11-12T12:14:38.446566Z","shell.execute_reply":"2024-11-12T12:14:38.455017Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Starts with negation","metadata":{}},{"cell_type":"code","source":"def starts_with_negation(sentence):\n    negation_words = r\"^(not|no|don't|doesn't|isn't|aren't|wasn't|weren't|won't|can't|couldn't|shouldn't|wouldn't|didn't|haven't|hasn't|hadn't|mustn't)\\b\"\n    \n    if re.match(negation_words, sentence.strip(), re.IGNORECASE):\n        return True\n    return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:14:00.924081Z","iopub.execute_input":"2024-11-12T12:14:00.92493Z","iopub.status.idle":"2024-11-12T12:14:00.92988Z","shell.execute_reply.started":"2024-11-12T12:14:00.924883Z","shell.execute_reply":"2024-11-12T12:14:00.92886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"negation_count = {'True': 0, 'False': 0}\n\n# Check each question for being a question and starting with negation\nfor item in phi_questions:\n    question_text = item['question']\n    \n    # Count results for starts_with_negation\n    if starts_with_negation(question_text):\n        negation_count['True'] += 1\n    else:\n        negation_count['False'] += 1\n\nnegation_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:14:44.259823Z","iopub.execute_input":"2024-11-12T12:14:44.260817Z","iopub.status.idle":"2024-11-12T12:14:44.270504Z","shell.execute_reply.started":"2024-11-12T12:14:44.260771Z","shell.execute_reply":"2024-11-12T12:14:44.269393Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:39:21.333569Z","iopub.execute_input":"2024-11-18T20:39:21.334405Z","iopub.status.idle":"2024-11-18T20:39:21.370814Z","shell.execute_reply.started":"2024-11-18T20:39:21.33437Z","shell.execute_reply":"2024-11-18T20:39:21.369733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = \"BAAI/bge-base-en-v1.5\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:39:21.54466Z","iopub.execute_input":"2024-11-18T20:39:21.545396Z","iopub.status.idle":"2024-11-18T20:39:29.033346Z","shell.execute_reply.started":"2024-11-18T20:39:21.54536Z","shell.execute_reply":"2024-11-18T20:39:29.032397Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# relevance to lisa sheet","metadata":{}},{"cell_type":"code","source":"def generate_embeddings(texts, model, tokenizer, device, batch_size=8):\n    all_embeddings = []\n    \n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n        with torch.no_grad():\n            outputs = model(**inputs)\n        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n        \n        all_embeddings.append(embeddings.cpu().numpy())\n    return np.concatenate(all_embeddings, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T20:39:29.184718Z","iopub.execute_input":"2024-11-18T20:39:29.185488Z","iopub.status.idle":"2024-11-18T20:39:29.192887Z","shell.execute_reply.started":"2024-11-18T20:39:29.185447Z","shell.execute_reply":"2024-11-18T20:39:29.191952Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nlisa_embeddings = generate_embeddings(cleaned_txt_contents, model, tokenizer, device)\n\nquestion_texts = [full_question['question'] for full_question in questions]\nquestion_embeddings = generate_embeddings(question_texts, model, tokenizer, device)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T20:39:39.185252Z","iopub.execute_input":"2024-11-18T20:39:39.186159Z","iopub.status.idle":"2024-11-18T20:39:47.41857Z","shell.execute_reply.started":"2024-11-18T20:39:39.186126Z","shell.execute_reply":"2024-11-18T20:39:47.417576Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lisa_texts = [q['content'] for q in phi_questions]\nlisa_embeddings_phi = generate_embeddings(lisa_texts, model, tokenizer, device)\n\nquestion_texts = [q['question'] for q in phi_questions]\nquestion_embeddings_phi = generate_embeddings(question_texts, model, tokenizer, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:39:47.420007Z","iopub.execute_input":"2024-11-18T20:39:47.420275Z","iopub.status.idle":"2024-11-18T20:39:54.127619Z","shell.execute_reply.started":"2024-11-18T20:39:47.42025Z","shell.execute_reply":"2024-11-18T20:39:54.126689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def to_tensor(embedding):\n    if isinstance(embedding, np.ndarray):\n        return torch.tensor(embedding)\n    return embedding\n\ndef cosine_similarity(embedding1, embedding2):\n    return F.cosine_similarity(embedding1, embedding2, dim=0).item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T20:39:54.128724Z","iopub.execute_input":"2024-11-18T20:39:54.129032Z","iopub.status.idle":"2024-11-18T20:39:54.13406Z","shell.execute_reply.started":"2024-11-18T20:39:54.129005Z","shell.execute_reply":"2024-11-18T20:39:54.132986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question_folder_embeddings","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selected_folders = list(question_folder_embeddings.keys())[:6]  # Define selected folders\n\n# Dictionary to store similarities for each folder\nfolder_direct_similarities = {}\n\nfor folder in selected_folders:\n    # Ensure both embeddings have the same number of items\n    lisa_embeds = lisa_folder_embeddings[folder]\n    question_embeds = question_folder_embeddings[folder]\n    \n    if len(lisa_embeds) == len(question_embeds):\n        # Calculate pairwise cosine similarity for matching indices\n        direct_similarities = [\n            cosine_similarity(lisa, question)\n            for lisa, question in zip(lisa_embeds, question_embeds)\n        ]\n        folder_direct_similarities[folder] = direct_similarities\n    else:\n        print(f\"Folder {folder} has mismatched embedding counts.\")\n\n# Plot cosine similarity distributions for selected folders\nplt.figure(figsize=(14, 8))\n\nfor i, folder in enumerate(selected_folders, 1):\n    plt.subplot(2, 3, i)  # Create a 2x3 grid for subplots\n    sns.histplot(folder_direct_similarities[folder], bins=20, color=\"skyblue\", edgecolor=\"black\")\n    plt.title(f\"Phi-3.5, calculate relevance in Folder: {folder}\")\n    plt.xlabel(\"Cosine Similarity\")\n    plt.ylabel(\"Frequency\")\n\nplt.tight_layout()\nplt.savefig(\"Phi-3.5_calculate_relevance.png\", dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:18:41.887399Z","iopub.execute_input":"2024-11-18T21:18:41.888285Z","iopub.status.idle":"2024-11-18T21:18:44.949911Z","shell.execute_reply.started":"2024-11-18T21:18:41.888239Z","shell.execute_reply":"2024-11-18T21:18:44.94906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lisa_folder_embeddings_gpt4o = defaultdict(list)\nfor item, embedding in zip(questions_with_folder, lisa_embeddings):\n    folder = item['folder']\n    lisa_folder_embeddings_gpt4o[folder].append(to_tensor(embedding))\n\nquestion_folder_embeddings_gpt4o = defaultdict(list)\nfor item, embedding in zip(questions, question_embeddings):\n    folder = item['folder']\n    question_folder_embeddings_gpt4o[folder].append(to_tensor(embedding))\n\n# Calculate cosine similarity for matching indices for the same folders as phi3.5\nfolder_direct_similarities_gpt4o = {}\n\nfor folder in selected_folders:  # Reuse the selected folders from phi3.5\n    lisa_embeds = lisa_folder_embeddings_gpt4o[folder]\n    question_embeds = question_folder_embeddings_gpt4o[folder]\n    \n    if len(lisa_embeds) == len(question_embeds):\n        # Calculate pairwise cosine similarity for matching indices\n        direct_similarities = [\n            cosine_similarity(lisa, question)\n            for lisa, question in zip(lisa_embeds, question_embeds)\n        ]\n        folder_direct_similarities_gpt4o[folder] = direct_similarities\n    else:\n        print(f\"Folder {folder} has mismatched embedding counts.\")\n\n# Plot cosine similarity distributions for selected folders (GPT4o)\nplt.figure(figsize=(14, 8))\n\nfor i, folder in enumerate(selected_folders, 1):\n    plt.subplot(2, 3, i)  # Create a 2x3 grid for subplots\n    sns.histplot(folder_direct_similarities_gpt4o[folder], bins=20, color=\"lightcoral\", edgecolor=\"black\")\n    plt.title(f\"GPT4o, calculate relevance in Folder: {folder}\")\n    plt.xlabel(\"Cosine Similarity\")\n    plt.ylabel(\"Frequency\")\n\nplt.tight_layout()\nplt.savefig(\"GPT4o_calculate_relevance.png\", dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:18:04.391655Z","iopub.execute_input":"2024-11-18T21:18:04.392508Z","iopub.status.idle":"2024-11-18T21:18:07.521504Z","shell.execute_reply.started":"2024-11-18T21:18:04.39247Z","shell.execute_reply":"2024-11-18T21:18:07.520717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check relevance question to each .txt filde withoing folder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate ordered cosine similarities\ndef calculate_cosine_similarities_ordered(lisa_embeddings, question_embeddings):\n    lisa_embeddings = torch.tensor(lisa_embeddings)\n    question_embeddings = torch.tensor(question_embeddings)\n\n    ordered_similarities = [\n        cosine_similarity(lisa, question)\n        for lisa, question in zip(lisa_embeddings, question_embeddings)\n    ]\n    return ordered_similarities\n\n\ndef calculate_cosine_similarities_random(lisa_embeddings, question_embeddings):\n    # Ensure both embeddings are torch tensors\n    lisa_embeddings = torch.tensor(lisa_embeddings)\n    question_embeddings = torch.tensor(question_embeddings)\n    \n    # Shuffle question_embeddings randomly\n    random_question_embeddings = question_embeddings[torch.randperm(len(question_embeddings))]\n    \n    # Calculate cosine similarities in the random order\n    random_similarities = [\n        cosine_similarity(lisa, question)\n        for lisa, question in zip(lisa_embeddings, random_question_embeddings)\n    ]\n    return random_similarities","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:20:29.806089Z","iopub.execute_input":"2024-11-05T11:20:29.806735Z","iopub.status.idle":"2024-11-05T11:20:29.814567Z","shell.execute_reply.started":"2024-11-05T11:20:29.806693Z","shell.execute_reply":"2024-11-05T11:20:29.813651Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ordered_similarities = calculate_cosine_similarities_ordered(lisa_embeddings, question_embeddings)\nrandom_similarities = calculate_cosine_similarities_random(lisa_embeddings, question_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T11:20:35.877341Z","iopub.execute_input":"2024-11-05T11:20:35.878207Z","iopub.status.idle":"2024-11-05T11:20:35.921024Z","shell.execute_reply.started":"2024-11-05T11:20:35.878167Z","shell.execute_reply":"2024-11-05T11:20:35.920099Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_similarity_distributions(ordered_similarities, random_similarities):\n    plt.figure(figsize=(12, 6))\n    \n    plt.subplot(1, 2, 1)\n    plt.hist(ordered_similarities, bins=20, color='blue', alpha=0.7, edgecolor='black')\n    plt.title('Cosine Similarity Distribution - Input sheet')\n    plt.xlabel('Cosine Similarity')\n    plt.ylabel('Frequency')\n    \n    plt.subplot(1, 2, 2)\n    plt.hist(random_similarities, bins=20, color='orange', alpha=0.7, edgecolor='black')\n    plt.title('Cosine Similarity Distribution - Random')\n    plt.xlabel('Cosine Similarity')\n    plt.ylabel('Frequency')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-05T12:26:19.109853Z","iopub.execute_input":"2024-11-05T12:26:19.110635Z","iopub.status.idle":"2024-11-05T12:26:19.117658Z","shell.execute_reply.started":"2024-11-05T12:26:19.110594Z","shell.execute_reply":"2024-11-05T12:26:19.116639Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#GPT4\nplot_similarity_distributions(ordered_similarities, random_similarities)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PHI-3\nordered_similarities_phi = calculate_cosine_similarities_ordered(lisa_embeddings_phi, question_embeddings_phi)\nrandom_similarities_phi = calculate_cosine_similarities_random(lisa_embeddings_phi, question_embeddings_phi)\n\nplot_similarity_distributions(ordered_similarities_phi, random_similarities_phi)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cosine_similarity(embedding1, embedding2):\n    return F.cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0)).item()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T21:19:36.522084Z","iopub.execute_input":"2024-11-18T21:19:36.522769Z","iopub.status.idle":"2024-11-18T21:19:36.52688Z","shell.execute_reply.started":"2024-11-18T21:19:36.52274Z","shell.execute_reply":"2024-11-18T21:19:36.526004Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_pairwise_option_similarities(questions, model, tokenizer, device=\"cuda\"):\n    results = []\n    \n    for question_data in questions:\n        # Ensure options are a flat list of strings\n        options = [\n            question_data['option_a'],\n            question_data['option_b'],\n            question_data['option_c'],\n            question_data['option_d']\n        ]\n\n        # Generate embeddings for the options (flat list of strings)\n        embeddings = generate_embeddings(options, model, tokenizer, device)\n        \n        similarities = {\n            \"a_b\": cosine_similarity(torch.tensor(embeddings[0]), torch.tensor(embeddings[1])),\n            \"a_c\": cosine_similarity(torch.tensor(embeddings[0]), torch.tensor(embeddings[2])),\n            \"a_d\": cosine_similarity(torch.tensor(embeddings[0]), torch.tensor(embeddings[3])),\n            \"b_c\": cosine_similarity(torch.tensor(embeddings[1]), torch.tensor(embeddings[2])),\n            \"b_d\": cosine_similarity(torch.tensor(embeddings[1]), torch.tensor(embeddings[3])),\n            \"c_d\": cosine_similarity(torch.tensor(embeddings[2]), torch.tensor(embeddings[3]))\n        }\n\n        results.append({\n            \"question\": question_data['question'],\n            \"similarities\": similarities,\n            \"correct_option\": question_data['correct_option']\n        })\n    \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-11-18T21:19:36.740735Z","iopub.execute_input":"2024-11-18T21:19:36.741484Z","iopub.status.idle":"2024-11-18T21:19:36.748381Z","shell.execute_reply.started":"2024-11-18T21:19:36.741453Z","shell.execute_reply":"2024-11-18T21:19:36.747372Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"option_similarities = calculate_pairwise_option_similarities(questions, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T21:19:37.962462Z","iopub.execute_input":"2024-11-18T21:19:37.963217Z","iopub.status.idle":"2024-11-18T21:19:42.371069Z","shell.execute_reply.started":"2024-11-18T21:19:37.963184Z","shell.execute_reply":"2024-11-18T21:19:42.370273Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"option_similarities_phi = calculate_pairwise_option_similarities(phi_questions, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:19:42.372289Z","iopub.execute_input":"2024-11-18T21:19:42.372565Z","iopub.status.idle":"2024-11-18T21:19:46.374504Z","shell.execute_reply.started":"2024-11-18T21:19:42.372539Z","shell.execute_reply":"2024-11-18T21:19:46.373563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_similarity_histogram(results):\n    # Collect all similarity values\n    similarities = []\n    for result in results:\n        similarities.extend(result[\"similarities\"].values())\n    \n    # Plot histogram\n    plt.figure(figsize=(10, 6))\n    plt.hist(similarities, bins=20, color='skyblue', edgecolor='black')\n    plt.title(\"Distribution of Option Pair Similarities Across Questions\")\n    plt.xlabel(\"Cosine Similarity\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n# GPT4\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T21:19:46.376406Z","iopub.execute_input":"2024-11-18T21:19:46.377Z","iopub.status.idle":"2024-11-18T21:19:46.382278Z","shell.execute_reply.started":"2024-11-18T21:19:46.376962Z","shell.execute_reply":"2024-11-18T21:19:46.38143Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_similarity_histogram(option_similarities)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#PHI3\nplot_similarity_histogram(option_similarities_phi)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_ambiguity_similarity_boxplot(results, model_name):\n    \"\"\"\n    Plot ambiguity (1 - cosine similarity) for each option pair across questions.\n\n    Parameters:\n    - results: List of dictionaries with \"similarities\" and \"Pair\" keys.\n    - model_name: Name of the model (e.g., \"GPT4o\", \"Phi3.5\") to label the plot.\n    \"\"\"\n    data = {\"Pair\": [], \"Ambiguity\": []}\n    \n    # Transform similarities into ambiguity (1 - cosine similarity)\n    for result in results:\n        for pair, similarity in result[\"similarities\"].items():\n            data[\"Pair\"].append(pair)\n            data[\"Ambiguity\"].append(1 - similarity)\n    \n    df = pd.DataFrame(data)\n    \n    # Calculate the median ambiguity for each pair and sort in descending order\n    median_sorted_pairs = df.groupby(\"Pair\")[\"Ambiguity\"].median().sort_values(ascending=False).index\n    \n    # Plot box plot with sorted pairs in descending order of median ambiguity\n    plt.figure(figsize=(12, 6))\n    sns.boxplot(x=\"Pair\", y=\"Ambiguity\", data=df, order=median_sorted_pairs)\n    plt.title(f\"Ambiguity (1 - Cosine Similarity) by Option Pair ({model_name})\")\n    plt.xlabel(\"Option Pair\")\n    plt.ylabel(\"Ambiguity (1 - Cosine Similarity)\")\n    plt.tight_layout()\n    plt.savefig(f\"ambiguity_{model_name}.png\", dpi=300, bbox_inches='tight')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T21:25:03.189135Z","iopub.execute_input":"2024-11-18T21:25:03.18948Z","iopub.status.idle":"2024-11-18T21:25:03.196305Z","shell.execute_reply.started":"2024-11-18T21:25:03.189452Z","shell.execute_reply":"2024-11-18T21:25:03.195491Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # GPT4\nplot_ambiguity_similarity_boxplot(option_similarities, \"GPT4o\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T21:25:04.761434Z","iopub.execute_input":"2024-11-18T21:25:04.762061Z","iopub.status.idle":"2024-11-18T21:25:05.728676Z","shell.execute_reply.started":"2024-11-18T21:25:04.762026Z","shell.execute_reply":"2024-11-18T21:25:05.727777Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PHI3\nplot_ambiguity_similarity_boxplot(option_similarities_phi, \"Phi3.5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T21:25:30.333089Z","iopub.execute_input":"2024-11-18T21:25:30.334102Z","iopub.status.idle":"2024-11-18T21:25:31.270161Z","shell.execute_reply.started":"2024-11-18T21:25:30.334067Z","shell.execute_reply":"2024-11-18T21:25:31.269315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_correct_incorrect_similarities(questions, model, tokenizer, device=\"cuda\"):\n    results = []\n    \n    for question_data in questions:\n        # Extract options\n        options = {\n            \"a\": question_data['option_a'],\n            \"b\": question_data['option_b'],\n            \"c\": question_data['option_c'],\n            \"d\": question_data['option_d']\n        }\n        \n        embeddings = generate_embeddings(list(options.values()), model, tokenizer, device)\n        embeddings_dict = dict(zip(options.keys(), embeddings))  # Map option letters to embeddings\n        \n        correct_opt = question_data['correct_option'].lower()\n        if 'option' in correct_opt:\n            continue\n        correct_embedding = embeddings_dict[correct_opt]\n\n        \n        correct_incorrect_similarities = {}\n        for opt, embedding in embeddings_dict.items():\n            if opt != correct_opt:  # Only compare with incorrect options\n                pair_label = f\"{correct_opt}_{opt}\"  # Correct option always comes first\n                correct_incorrect_similarities[pair_label] = cosine_similarity(\n                    torch.tensor(correct_embedding), torch.tensor(embedding)\n                )\n        \n        results.append({\n            \"question\": question_data['question'],\n            \"similarities\": correct_incorrect_similarities,\n            \"correct_option\": question_data['correct_option']\n        })\n    \n    return results\n\n\ncorrect_incorrect_similarities = calculate_correct_incorrect_similarities(questions, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:28:55.335254Z","iopub.execute_input":"2024-11-12T12:28:55.336075Z","iopub.status.idle":"2024-11-12T12:29:00.336145Z","shell.execute_reply.started":"2024-11-12T12:28:55.336033Z","shell.execute_reply":"2024-11-12T12:29:00.335126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_correct_incorrect_similarity_boxplot(results):\n    data = {\"Pair\": [], \"Cosine Similarity\": []}\n    for result in results:\n        for pair, similarity in result[\"similarities\"].items():\n            data[\"Pair\"].append(pair)\n            data[\"Cosine Similarity\"].append(similarity)\n    \n    df = pd.DataFrame(data)\n    \n    # Calculate the median cosine similarity for each pair and sort in descending order\n    median_sorted_pairs = df.groupby(\"Pair\")[\"Cosine Similarity\"].median().sort_values(ascending=False).index\n    \n    # Plot the box plot with pairs sorted by median similarity in descending order\n    plt.figure(figsize=(12, 6))\n    sns.boxplot(x=\"Pair\", y=\"Cosine Similarity\", data=df, order=median_sorted_pairs)\n    plt.title(\"Cosine Similarity between Correct and Incorrect Options (Correct Option First, Sorted by Median)\")\n    plt.xlabel(\"Option Pair (Sorted by Median Similarity)\")\n    plt.ylabel(\"Cosine Similarity\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:30:15.135897Z","iopub.execute_input":"2024-11-12T12:30:15.136796Z","iopub.status.idle":"2024-11-12T12:30:15.144753Z","shell.execute_reply.started":"2024-11-12T12:30:15.136756Z","shell.execute_reply":"2024-11-12T12:30:15.143677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#plot_correct_incorrect_similarity_boxplot(correct_incorrect_similarities)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correct_incorrect_similarities_phi = calculate_correct_incorrect_similarities(phi_questions, model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:29:22.69124Z","iopub.execute_input":"2024-11-12T12:29:22.692025Z","iopub.status.idle":"2024-11-12T12:29:26.9366Z","shell.execute_reply.started":"2024-11-12T12:29:22.691978Z","shell.execute_reply":"2024-11-12T12:29:26.935592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Phi3\nplot_correct_incorrect_similarity_boxplot(correct_incorrect_similarities_phi)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}